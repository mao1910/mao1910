<!-- VISITOR BADGE -->
<!-- https://github.com/hehuapei/visitor-badge -->

<img align="right" src="https://visitor-badge.laobi.icu/badge?page_id=mao1910.mao1910&left_color=%2379DAF9&right_color=%23FE6E96" />


<!-- TYPING SVG -->
<!-- https://github.com/DenverCoder1/readme-typing-svg -->

<h1 align="center">
    <img src="https://readme-typing-svg.herokuapp.com/?font=Righteous&size=35&center=true&vCenter=true&width=500&height=70&color=FE6E96&font=poppins&duration=5000&lines=Hi+There!+üëã;+I'm+Mao!;" />
</h1>

<br/>

<!-- CODE/TERMINAL ABOUT ME -->
<h1 align="center">
<img src="./assets/terminal-5.gif" alt="Terminal" />
</h1>

<br/><br/><br/>


<!-- TECHNOLOGIES LOGOS -->
<!-- https://github.com/tandpfun/skill-icons -->

<h2 align="center">üíª Languages / Frameworks / Tools ‚öíÔ∏è</h2>
<div align="center">
    <img src="https://skillicons.dev/icons?i=javascript,typescript,angular,react,html,css,scss,bootstrap,cs,java,spring" />
    <img src="https://skillicons.dev/icons?i=flutter,firebase,supabase,mysql,git,github,gitlab,vscode,idea,maven,figma" />
</div>

<br/><br/><br/>


<!-- CONTRIBUTIONS SNAKE GAME -->
<!-- https://github.com/Platane/snk -->

<div align="center">
  <h2> My Contributionssssüêç </h2>
  <br>
  <img alt="contributions-eating Snake" src="https://raw.githubusercontent.com/mao1910/mao1910/output/github-contribution-grid-snake.svg" />

  <!-- Four lines below suggested by Planate for Dark mode-->
  <picture>
  <source media="(prefers-color-scheme: dark)" srcset="github-snake-dark.svg" />
  <source media="(prefers-color-scheme: light)" srcset="github-snake.svg" />
  </picture>
  
  <br/><br/><br/>
</div>


<!-- GITHUB STATS -->
<!-- https://github.com/DenverCoder1/github-readme-streak-stats -->
<!-- https://github.com/anuraghazra/github-readme-stats -->
<!-- https://github-readme-stats-mao1910.vercel.app/ My own Vercel deployment-->

<h2 align="center"> Statsüìù </h2>
  <br>
<div align=center>
  <img width=429 src="https://github-readme-stats-mao1910.vercel.app/api?username=mao1910&count_private=true&show_icons=true&theme=dracula&rank_icon=github&hide=contribs&border_radius=10&border_color=79DAF9" alt="github stats"/>
  <img width=396 src="https://streak-stats.demolab.com/?user=mao1910&count_private=true&theme=dracula&currStreakNum=79DAF9&currStreakLabel=FE6E96&border_radius=10&border=79DAF9" alt="streak stats"/>
  <br/>
  <img src="https://github-readme-stats-mao1910.vercel.app/api/top-langs/?username=mao1910&layout=compact&theme=dracula&border_radius=10&size_weight=0.5&count_weight=0.5&border_color=79DAF9" alt="languages stats" />
</div>

<br/><br/><br/>


<!-- FOOTER -->
<!-- https://github.com/DenverCoder1/readme-typing-svg -->
<!-- https://readme-typing-svg.demolab.com/demo/ -->

<a href="https://git.io/typing-svg"><img src="https://readme-typing-svg.demolab.com?font=Poppins&pause=1000&color=FE6E96&width=535&lines=Thanks+for+dropping+by!;Feel+free+to+check+any+of+the+Socials+below+%F0%9F%91%87;Or+the+Joke+Of+The+Day+if+you're+down+for+a+giggle+%F0%9F%98%9D;Hope+to+see+you+again+%F0%9F%91%8A;Uh%3F+You're+still+here%3F;Well...+I'm+running+out+of+things+to+say...;Tell+you+what%2C+due+to+your+effort+and+perseverance%2C;I+shall+present+you+with+a+short+poem%3A;%22To+code%2C+or+not+to+code%2C+that+is+the+question%3A;Whether+'tis+nobler+in+the+IDE+to+debug;The+errors+and+issues+of+outrageous+software%2C;Or+to+take+up+the+keyboard+against+a+sea+of+bugs;And+by+coding%2C+end+them.%22;by+William+Shakespeare%2C+probably.+;Pretty+sure+that's+Hamlet's.;Alrighty%2C+this+has+been+fun.;But+I'll+restart+the+loop+now...+see+ya+soon!" alt="Typing SVG" /></a>


<!--  SOCIAL NETWORKS -->
<!-- https://github.com/alexandresanlim/Badges4-README.md-Profile -->

  <div> 
    <a href="https://www.deviantart.com/madeinkobaia/art/my-profile-is-under-construction-265626465" target="_blank"><img src="https://img.shields.io/badge/-LinkedIn-%230077B5?style=for-the-badge&logo=linkedin&logoColor=white" target="_blank"></a> <!-- ADD LINKEDIN PROFILE -->
    <a href = "https://www.nicepng.com/ourpic/u2q8o0t4t4r5o0r5_website-under-construction-png-graphic-transparent-website-under/"><img src="https://img.shields.io/badge/Portfolio-4285F4?style=for-the-badge&logo=Google-chrome&logoColor=white" target="_blank"></a> <!-- ADD PORTFOLIO WEBSITE -->
    <a href="https://discord.gg" target="_blank"><img src="https://img.shields.io/badge/Discord-7289DA?style=for-the-badge&logo=discord&logoColor=white" target="_blank"></a> <!-- ADD DISCORD -->
    <a href = "mailto:mao1910dev@gmail.com"><img src="https://img.shields.io/badge/Gmail-D14836?style=for-the-badge&logo=gmail&logoColor=white" target="_blank"></a>
  </div>


<!-- SPOTIFY PLAYING-->
<!-- https://github.com/novatorem/novatorem -->
<!-- https://spotify-now-playing-novatorem-git-main-mao1910.vercel.app/ My own Vercel deployment-->

[<img width=438px src="https://spotify-now-playing-git-main-mao1910.vercel.app//api/spotify/?border_color=FE6E96" alt="Mao Spotify Now Playing" />](https://open.spotify.com/user/31542et242zglhf42ydrtqgvuvde)


<!-- JOKE OF THE DAY -->
<!-- https://github.com/ABSphreak/readme-jokes -->
<!-- https://readme-jokes-git-master-mao1910.vercel.app/ My own Vercel deployment-->

<details>
<summary>I've got a Joke for you. Wanna hear it? üôà</summary>

<br/>

 <tr>
 <td style="padding-top:4px"><img src = "https://readme-jokes-git-master-mao1910.vercel.app/api?&theme=dracula"></td>
 </tr>

</details>


<!-- RSS FEED -->
<!-- https://github.com/gautamkrishnar/blog-post-workflow -->

<details>
<summary>üìï &nbsp;RSS feed</summary>

<br/>

<!-- BLOG-POST-LIST:START -->
 #### - [What is your Why?](https://dev.to/acoh3n/what-is-your-why-j9b) 
 <details><summary>Article</summary> <p>I believe we all entered the field of programming for various reasons. It could be to earn a living, pursue a sought-after career, or simply because we love building stuff. Whatever the reason, we're here.</p>

<p>However, if I'm being perfectly honest, while all these are good reasons, none would provide me with more than the bare minimum level of happiness at what I do almost every day for many hours.</p>

<p>Yet, while I had my fair share of miserable days on the job like everyone else, more often than not, I am truly eager to do my thing at work. </p>

<p>So today, while I was running, I found myself in a bit of an introspective mood and wondered what is my personal Why? Why do I still love programming so much after all these years. </p>

<p>I always knew it had something to do with people. Seeing someone using something I wrote and maybe even liking it never ceases to give me a kick. But I felt there was a deeper desire. </p>

<p>After a little back and forth with myself I reduced it to something that felt really true for me: <strong>to reduce the suffering of someone else</strong>. Okay, I know it sounds a bit overly dramatic, but hear me out here for a minute. </p>

<p>Our profession is riddled with sharp objects we all occasionally bump into. People much smarter than myself say that it takes <a href="https://norvig.com/21-days.html">a very long</a> time to even begin to master it, there is formidable math and sophisticated algorithms lurking at every corner, then there are new languages, tools, frameworks and paradigms jumping on us every other day that threaten to undermine everything we've learned for the past however many years. </p>

<p>So when I get to brighten someone's day through my work in even the smallest way, damn it it feels good. </p>

<p>It could be a user that with the help of something I wrote suddenly feels much more productive, or it could be as "small" as assisting a colleague by showing them how to use some tool that I take for granted, but is life-changing for them. </p>

<p>That's why I relish at the opportunity to spend that extra hour at making my API just a tiny bit simpler, or clean up and refactor some messy code, or write that extra page of documentation or test. Because someone (including myself) will experience just a tiny bit less frustration and pain down the road when they try to use it. </p>

<p>And whenever I get to see it first hand it gives me the energy to wake up the next day and do it all over again. </p>

<p>So now I'd like to invite you to find your personal Why, and to please share it with us.</p>

 </details> 
 <hr /> 

 #### - [Extens√µes do Visual Studio Code para um Front-end](https://dev.to/manzoliric/extensoes-do-visual-studio-code-para-um-front-end-2pgk) 
 <details><summary>Article</summary> <p>Hoje vim trazer extens√µes do Visual Studio Code que eu uso e que me ajudam muito no dia a dia, esse post foi inspirado no post <a href="https://dev.to/laryssa/extensoes-do-visual-studio-code-para-um-sre-2nj5">Extens√µes do Visual Studio Code para um SRE</a> da <a href="https://dev.to/laryssa">Laryssa Araujo</a> onde ela mostra as ferramentas que ela usa no dia a dia como uma SRE.</p>

<p>N√£o vou falar sobre todas as extens√µes que eu tenho instalado aqui, tenho algumas para mexer com Elixir/Phoenix, Docker e etc... vou falar apenas das que eu mais uso e que me ajudam no dia a dia como Front-end.</p>

<ol>
<li><p><a href="https://marketplace.visualstudio.com/items?itemName=formulahendry.auto-rename-tag">Auto Rename Tag</a>: Essa extens√£o √© muito √∫til para quem trabalha com HTML, ela renomeia a tag de abertura e fechamento automaticamente, evitando que voc√™ tenha que ficar renomeando as tags manualmente.</p></li>
<li><p><a href="https://marketplace.visualstudio.com/items?itemName=streetsidesoftware.code-spell-checker">Code Spell Checker</a>: Essa extens√£o √© muito √∫til para corrigir erros de digita√ß√£o, ela verifica a palavra e mostra se existe algum erro de digita√ß√£o, exemplo quando escrevemos <code>lenght</code> ao inv√©s de <code>length</code>, que acontece muito comigo.</p></li>
<li><p><a href="https://marketplace.visualstudio.com/items?itemName=streetsidesoftware.code-spell-checker-portuguese-brazilian">Brazilian Portuguese - Code Spell Checker</a>: Essa extens√£o √© uma extens√£o da extens√£o anterior, ela adiciona um dicion√°rio de palavras em portugu√™s, para que a extens√£o anterior possa verificar as palavras em portugu√™s.</p></li>
<li><p><a href="https://marketplace.visualstudio.com/items?itemName=SimonSiefke.svg-preview">Svg Preview</a>: Essa extens√£o mostra uma pr√©via do SVG direto no VSCode, assim voc√™ n√£o precisa abrir o arquivo no navegador para ver o svg.</p></li>
<li><p><a href="https://marketplace.visualstudio.com/items?itemName=Equinusocio.vsc-community-material-theme">Community Material Theme</a>: Essa extens√£o √© apenas o tema que eu mais gosto, gosto de usar a vers√£o <code>Material Theme Darker</code>.</p></li>
<li><p><a href="https://marketplace.visualstudio.com/items?itemName=PKief.material-icon-theme">Material Icon Theme</a>: Essa extens√£o √© apenas o tema de √≠cones que eu mais gosto.</p></li>
<li><p><a href="https://marketplace.visualstudio.com/items?itemName=wix.vscode-import-cost">Import Cost</a>: Essa extens√£o mostra o tamanho do pacote que voc√™ est√° importando, assim voc√™ pode ver se o pacote √© muito grande e se vale a pena usar ele.</p></li>
<li><p><a href="https://marketplace.visualstudio.com/items?itemName=eamodio.gitlens">Git Lens</a>: Essa extens√£o √© bem completa, tem muita coisa, mas para falar a verdade eu uso muito ela para verificar quem fez a √∫ltima altera√ß√£o no arquivo direto no VSCode e tamb√©m conseguir ir direto para o arquivo no GitHub ou Pull Request.</p></li>
<li><p><a href="https://marketplace.visualstudio.com/items?itemName=GitHub.copilot">GitHub Copilot</a>: Essa extens√£o n√£o tem muito que dizer, √© o famoso GitHub Copilot, tem me ajudado bastante a criar c√≥digos que s√£o mais repetitivos,e tamb√©m funciona muito bem para documenta√ß√£o e coment√°rios.</p></li>
<li><p><a href="https://marketplace.visualstudio.com/items?itemName=EditorConfig.EditorConfig">EditorConfig for VS Code</a>: Essa extens√£o √© muito √∫til para quem trabalha em projetos com v√°rias pessoas, ela ajuda a manter o padr√£o de c√≥digo, como por exemplo, <code>indent_style</code>, <code>indent_size</code>, <code>insert_final_newline</code> e etc... criamos um arquivo <code>.editorconfig</code> na raiz do projeto e configuramos o que queremos que seja o padr√£o.</p></li>
</ol>

 </details> 
 <hr /> 

 #### - [PHP e o Machine Learning](https://dev.to/lenog/php-e-o-machine-learning-3b2b) 
 <details><summary>Article</summary> <p>Nos √∫ltimos anos, o Machine Learning se tornou uma ferramenta indispens√°vel em uma ampla variedade de aplica√ß√µes, desde recomenda√ß√£o de produtos at√© diagn√≥stico m√©dico. Embora seja comumente associado a linguagens como Python e R, √© poss√≠vel aplicar t√©cnicas de Machine Learning em PHP com a ajuda da biblioteca Rubix.</p>

<p>O PHP √© uma linguagem de programa√ß√£o amplamente utilizada para desenvolvimento web, e muitos desenvolvedores j√° est√£o familiarizados com ela. A introdu√ß√£o do Rubix oferece uma maneira poderosa de aproveitar os recursos de Machine Learning em PHP e expandir o escopo de projetos em que a linguagem pode ser aplicada.</p>




<h2>
  
  
  O que √© o Rubix?
</h2>

<p>O Rubix √© uma biblioteca de c√≥digo aberto para Machine Learning em PHP que foi desenvolvida para ser amig√°vel e acess√≠vel para desenvolvedores PHP. Ele oferece suporte para uma ampla variedade de algoritmos de Machine Learning, como regress√£o linear, √°rvores de decis√£o, k-means e muito mais.</p>

<p>O Rubix fornece uma API intuitiva e bem documentada que permite aos desenvolvedores criar e treinar modelos de Machine Learning, realizar previs√µes e avaliar o desempenho dos modelos. Al√©m disso, a biblioteca possui recursos de pr√©-processamento de dados e valida√ß√£o cruzada para ajudar a garantir que os modelos sejam constru√≠dos de maneira eficaz.</p>




<h2>
  
  
  Por que usar Machine Learning em PHP com o Rubix?
</h2>

<p>H√° v√°rias raz√µes pelas quais pode ser ben√©fico utilizar o Rubix para Machine Learning em PHP:</p>

<p><strong>Integra√ß√£o Simples:</strong> O Rubix √© f√°cil de integrar em projetos PHP existentes. Voc√™ pode incorporar facilmente funcionalidades de Machine Learning em seu aplicativo da web ou sistema existente.</p>

<p><strong>Familiaridade com PHP:</strong> Para desenvolvedores que j√° est√£o familiarizados com PHP, n√£o √© necess√°rio aprender uma nova linguagem como Python ou R para trabalhar com Machine Learning. Isso pode economizar tempo e esfor√ßo.</p>

<p><strong>Ecossistema PHP:</strong> O Rubix se encaixa bem no ecossistema PHP e pode ser facilmente combinado com outras bibliotecas e frameworks PHP, aproveitando todo o ecossistema de PHP.</p>

<p><strong>Comunidade Ativa:</strong> O Rubix tem uma comunidade ativa de desenvolvedores que contribuem para a biblioteca e oferecem suporte. Isso significa que voc√™ pode obter ajuda e encontrar recursos online facilmente.</p>




<h2>
  
  
  Como come√ßar com o Rubix
</h2>

<p>Para come√ßar a usar o Rubix para Machine Learning em PHP, siga estas etapas:</p>

<p><strong>Instala√ß√£o:</strong> Voc√™ pode instalar o Rubix usando o Composer, que √© uma ferramenta de gerenciamento de depend√™ncias PHP. Basta adicionar a biblioteca Rubix ao seu arquivo composer.json e executar o comando composer install.</p>

<p><strong>Carregando Dados:</strong> O primeiro passo √© carregar seus dados em uma estrutura de dados compat√≠vel com o Rubix. Isso pode ser feito com arrays ou objetos, dependendo do seu caso de uso.</p>

<p><strong>Pr√©-processamento de Dados:</strong> O Rubix fornece ferramentas para pr√©-processar seus dados, como normaliza√ß√£o e codifica√ß√£o de vari√°veis categ√≥ricas.</p>

<p><strong>Constru√ß√£o do Modelo:</strong> Escolha um algoritmo de Machine Learning e construa um modelo usando a API do Rubix.</p>

<p><strong>Treinamento do Modelo:</strong> Alimente seus dados de treinamento no modelo para que ele aprenda os padr√µes nos dados.</p>

<p><strong>Avalia√ß√£o do Modelo:</strong> Avalie o desempenho do modelo usando m√©tricas apropriadas, como precis√£o, recall e F1-score.</p>

<p><strong>Previs√µes:</strong> Use o modelo treinado para fazer previs√µes em novos dados.</p>

<p><strong>Itera√ß√£o:</strong> Refine seu modelo, ajuste hiperpar√¢metros e continue melhorando seu desempenho.</p>




<h2>
  
  
  Exemplo de uso do Rubix
</h2>

<p>Aqui est√° um exemplo simples de como usar o Rubix para criar um modelo de regress√£o linear em PHP:<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>use Rubix\ML\Regressors\LinearRegression;

// Carregar dados
$data = [...]; // Seus dados aqui

// Inicializar o modelo
$estimator = new LinearRegression();

// Treinar o modelo
$estimator-&gt;train($data);

// Fazer uma previs√£o
$prediction = $estimator-&gt;predict([1.5, 2.0, 3.7]);

echo 'Previs√£o: ' . $prediction;
</code></pre>

</div>



<p>Este √© apenas um exemplo b√°sico, e o Rubix oferece suporte a uma ampla variedade de algoritmos e t√©cnicas de Machine Learning para atender a diferentes necessidades.</p>

<p>Para um exemplo pr√°tico e mais preciso, disponibilizei no meu GitHub um projeto simples de Machine Learning que, usando uma plan√≠lha com o hist√≥rico de vendas de diversos carros e suas caracter√≠sticas, com milhares de registros, consegue prever se um carro novo que n√£o consta na plan√≠lha seria provavelmente vendido ou n√£o, de acordo com suas caracter√≠sticas. O projeto est√° dispon√≠vel no link: <a href="https://github.com/leo-nog/php-simple-machine-learning">https://github.com/leo-nog/php-simple-machine-learning</a></p>




<h2>
  
  
  Conclus√£o
</h2>

<p>O Rubix √© uma biblioteca valiosa que permite que os desenvolvedores de PHP explorem e aproveitem os benef√≠cios do Machine Learning em seus projetos. Com sua API intuitiva e ampla gama de recursos, o Rubix torna mais f√°cil do que nunca criar modelos de Machine Learning em PHP e aplic√°-los em diversos dom√≠nios.</p>

<p>Se voc√™ √© um desenvolvedor PHP que deseja adicionar recursos de Machine Learning aos seus projetos, o Rubix √© uma excelente escolha que oferece potencial e flexibilidade para atender √†s suas necessidades. Comece a explorar o mundo do Machine Learning com PHP e o Rubix e descubra o que voc√™ pode alcan√ßar.</p>

 </details> 
 <hr /> 

 #### - [If you have these three things, then you‚Äôre a user (and not a programmer)](https://dev.to/noriller/if-you-have-these-three-things-then-youre-a-user-and-not-a-programmer-45nk) 
 <details><summary>Article</summary> <p>2023/09/13 is the 256 day of the year or in other words, Programmer‚Äôs Day.</p>

<p>Take this chance to congratulate yourself, your colleagues, or a programmer friend.</p>

<blockquote>
<p><strong>Disclaimer</strong>: the author take no responsibility for the trip to the nearest dark place your programmer friend might be in.</p>
</blockquote>

<h2>
  
  
  Programmer or user?
</h2>

<p>In other years ([<a href="https://dev.to/noriller/if-you-have-these-three-things-you-can-be-a-programmer-too-v2-2e56">2022</a>, <a href="https://dev.to/noriller/if-you-have-this-three-things-you-can-be-a-programmer-too-28b8">2021</a>]) I‚Äôve talked about things that make you a Programmer, but this time around I enumerated a few things that might show that you might not be a programmer, but (<em>suspense noises</em>) just a user.</p>

<p>Please note that everyone <em>is</em> a user of something, that is not a problem. But if you say you‚Äôre a programmer, but all you do is be a user, then you have a <code>TypeError: User is not of type Programmer</code>.</p>

<h2>
  
  
  1. You don't read error messages
</h2>

<p>I‚Äôve worked a lot with digitally illiterate people of many levels and the one thing that stood out was how fast they would click an error message out of view.</p>

<p>Then there I went, did what they were doing, <strong>actually</strong> read the error message, and <em>magic!</em> solved the problem.</p>

<p>I saw ‚Äúprogrammers‚Äù who do something similar, choosing to ignore any error messages, trying to run whatever they‚Äôre doing again, and, of course, failing.</p>

<p>Sometimes, all it takes is just reading the error messages. Other times, you read, google it, open the first link, and follow the instructions. <em>Presto!</em></p>

<p>Other times, you have to bang your two neurons a little harder, tracing the steps of the software to pinpoint the exact point of failure, and then facepalm yourself hard enough because it was something so simple.</p>

<p>Finally, a few times you read the error, then backtraced the problem and still you and ChatGPT have no idea how to solve it. So, you read the <strong><a href="https://stackoverflow.com/help/how-to-ask">How do I ask a good question?</a></strong> page from StackOverflow and wherever you usually do a good question so people can easily help you.</p>

<h2>
  
  
  2. You‚Äôre content with software
</h2>

<p>The more junior you are the more you probably think: ‚ÄúI can do it better‚Äù.</p>

<p>On the other side, the more senior you get, probably the more pissed you get with badly written websites and apps. You also probably appreciate good interactions a lot more.</p>

<p>This is if you‚Äôre a programmer, but when you‚Äôre a user‚Ä¶ You just don‚Äôt care.</p>

<p>You might think you can just jump the hoops and loops and all those problems are nothing to get worked over. You‚Äôre complacent and only the very worst will make you complain or abandon it.</p>

<p>No matter who you are, we always end up drawing a line where from one point forward we are programmers but the rest we are users. The question is where did you draw yours?</p>

<p>The language? The framework? The meta framework? The libs? Just whatever you‚Äôre doing?</p>

<p>Some people might never have thought about actually influencing the things and tools they use every day. You might not have time or skill to actually fix something, but you see something you use and feel like it could be improved with something or you have the same problem over and over‚Ä¶ have you ever tried opening an Issue in the project repo?</p>

<p>Maybe more people have the same problem or more people would enjoy the improvements of your idea, someone might jump into implementing that if only they see your Issue. But when you just don‚Äôt care enough, then nothing will happen.</p>

<h2>
  
  
  3. You‚Äôre superstitious (it‚Äôs how it was always done)
</h2>

<p>This one touches the other ones. The superstitious ‚Äúprogrammer‚Äù (or user) is someone who does things because ‚Äúit was how it was always done‚Äù.</p>

<p>I can argue that you don‚Äôt actually know what in the name of binary you‚Äôre doing, because you just copy and paste code, change things here and there, and hope it works. I‚Äôve met that kind of ‚Äúprogrammer‚Äù and nowadays one of its names is ChatGPT.</p>

<p>ChatGPT is a grand example because it doesn't know anything. It just saw enough it can just spill enough bullshit that sometimes it actually makes sense and works.</p>

<p>jQuery still works to this day, but is it the best way of doing things today? While jumping at the newest framework would definitely make you a programmer, it‚Äôs not something sustainable.</p>

<p>A programmer has to evaluate both ends and find the one that is the best choice for today and for the foreseeable future, always considering where they are coming from.</p>

<p>In a new project, this is easier, but in a legacy project this might be a rewrite or more likely, adding a new way of doing things where you don‚Äôt need to rewrite things already working, but gives you a better tool to migrate crucial parts and create new features.</p>




<p>Cover Photo by <a href="https://unsplash.com/@thisisengineering?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">ThisisEngineering RAEng</a> on <a href="https://unsplash.com/photos/iQqRM0XJvn8?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></p>

 </details> 
 <hr /> 

 #### - [Build an AI SMS Chatbot with Replicate, LLaMA 2, and LangChain](https://dev.to/twilio/build-an-ai-sms-chatbot-with-replicate-llama-2-and-langchain-3i72) 
 <details><summary>Article</summary> <p>Recently, Meta and Microsoft introduced the second generation of the LLaMA LLM (Large Language Model) to help developers and organizations to build generative AI-powered tools and experiences. Read on to learn how to build an AI SMS chatbot that answers questions like Ahsoka (from Star Wars) using LangChain templating, LLaMa 2, Replicate, and Twilio Programmable Messaging!<br>
<a href="https://res.cloudinary.com/practicaldev/image/fetch/s--YtzI9bA---/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/c11hzs7x148okb1zjlj3.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--YtzI9bA---/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/c11hzs7x148okb1zjlj3.png" alt="SMS example" width="800" height="197"></a><br>
Do you prefer learning via video more? Check out <a href="https://www.tiktok.com/@lizziepikachu/video/7278020285750889774">this TikTok summarizing this tutorial</a> in 1 minute!</p>
<h3>
  
  
  Prerequisites
</h3>

<ol>
<li>A Twilio account - <a href="https://www.twilio.com/try-twilio">sign up for a free Twilio account here</a>
</li>
<li>A Twilio phone number with SMS capabilities - <a href="https://support.twilio.com/hc/en-us/articles/223135247-How-to-Search-for-and-Buy-a-Twilio-Phone-Number-from-Console">learn how to buy a Twilio Phone Number here</a>
</li>
<li>Replicate account to host the LlaMA 2 model ‚Äì <a href="https://replicate.com/signin?next=/">make a Replicate account here</a>
</li>
<li>Python installed - <a href="https://www.python.org/downloads/">download Python here</a>
</li>
<li>
<a href="https://ngrok.com/download">ngrok</a>, a handy utility to connect the development version of our Python application running on your machine to a public URL that Twilio can access.</li>
</ol>

<p>‚ö†Ô∏è <strong>ngrok is needed for the development version of the application because your computer is likely behind a router or firewall, so it isn‚Äôt directly reachable on the Internet. You can also choose to automate ngrok as shown in this article.</strong></p>
<h3>
  
  
  Replicate
</h3>

<p>Replicate offers a cloud API and tools so you can more easily run machine learning models, abstracting away some lower-level machine learning concepts and handling infrastructure so you can focus more on your own applications. You can run open-source models that others have published, or package and publish your own, either publicly or privately.</p>
<h3>
  
  
  Configuration
</h3>

<p>Since you will be installing some Python packages for this project, you will need to make a new project directory and a <a href="https://docs.python.org/3/tutorial/venv.html">virtual environment</a>.</p>

<p>If you're using a Unix or macOS system, open a terminal and enter the following commands:<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight shell"><code><span class="nb">mkdir </span>replicate-llama-ai-sms-chatbot  
<span class="nb">cd </span>replicate-llama-ai-sms-chatbot  
python3 <span class="nt">-m</span> venv venv 
<span class="nb">source </span>venv/bin/activate 
pip <span class="nb">install </span>langchain replicate flask twilio
</code></pre>

</div>



<p>If you're following this tutorial on Windows, enter the following commands in a command prompt window:<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight shell"><code><span class="nb">mkdir </span>replicate-llama-ai-sms-chatbot  
<span class="nb">cd </span>replicate-llama-ai-sms-chatbot   
python <span class="nt">-m</span> venv venv 
venv<span class="se">\S</span>cripts<span class="se">\a</span>ctivate 
pip <span class="nb">install </span>langchain replicate flask twilio
</code></pre>

</div>



<p><a href="https://replicate.com/account/api-tokens">Grab your default Replicate API Token or create a new one here</a>.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--GbpFlrL6--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/aat6zydxbdnq8sohcc4x.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--GbpFlrL6--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/aat6zydxbdnq8sohcc4x.png" alt="Replicate console" width="800" height="226"></a><br>
On the command line run<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight shell"><code><span class="nb">export </span><span class="nv">REPLICATE_API_TOKEN</span><span class="o">={</span>replace with your api token<span class="o">}</span>
</code></pre>

</div>



<p>Now it's time to write some code!</p>

<h3>
  
  
  Code
</h3>

<p>Make a file called <em>app.py</em> and place the following import statements at the top.<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight python"><code><span class="kn">from</span> <span class="nn">flask</span> <span class="kn">import</span> <span class="n">Flask</span><span class="p">,</span> <span class="n">request</span>
<span class="kn">from</span> <span class="nn">langchain</span> <span class="kn">import</span> <span class="n">LLMChain</span><span class="p">,</span> <span class="n">PromptTemplate</span>
<span class="kn">from</span> <span class="nn">langchain.llms</span> <span class="kn">import</span> <span class="n">Replicate</span>
<span class="kn">from</span> <span class="nn">langchain.memory</span> <span class="kn">import</span> <span class="n">ConversationBufferWindowMemory</span>
<span class="kn">from</span> <span class="nn">twilio.twiml.messaging_response</span> <span class="kn">import</span> <span class="n">MessagingResponse</span>
</code></pre>

</div>



<p>Though LLaMA 2 is tuned for chat, templates are still helpful so the LLM knows what behavior is expected of it. This starting prompt is similar to ChatGPT so it should behave similarly.<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight python"><code><span class="n">template</span> <span class="o">=</span> <span class="s">"""Assistant is a large language model.

Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.

Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.

Overall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist. 

I want you to act as Ahsoka giving advice and answering questions. You will reply with what she would say.
SMS: {sms_input}
Assistant:"""</span>

<span class="n">prompt</span> <span class="o">=</span> <span class="n">PromptTemplate</span><span class="p">(</span><span class="n">input_variables</span><span class="o">=</span><span class="p">[</span><span class="s">"sms_input"</span><span class="p">],</span> <span class="n">template</span><span class="o">=</span><span class="n">template</span><span class="p">)</span>
</code></pre>

</div>



<p>Next, make a LLM Chain, one of the core components of LangChain. This allows us to chain together prompts and make a prompt history. The model is formatted as the model name followed by the version‚Äìin this case, the model is LlaMA 2, a 13-billion parameter language model from Meta fine-tuned for chat completions. <code>max_length</code> is 4096, the maximum number of tokens (called the <em>context window</em>) the LLM can accept as input when generating responses.<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight python"><code><span class="n">sms_chain</span> <span class="o">=</span> <span class="n">LLMChain</span><span class="p">(</span>
    <span class="n">llm</span> <span class="o">=</span> <span class="n">Replicate</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="s">"a16z-infra/llama13b-v2-chat:df7690f1994d94e96ad9d568eac121aecf50684a0b0963b25a41cc40061269e5"</span><span class="p">),</span> 
    <span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>
    <span class="n">memory</span><span class="o">=</span><span class="n">ConversationBufferWindowMemory</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span>
    <span class="n">llm_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s">"max_length"</span><span class="p">:</span> <span class="mi">4096</span><span class="p">}</span>
<span class="p">)</span>
</code></pre>

</div>



<p>Finally, make a Flask app to accept inbound text messages, pass that to the LLM Chain, and return the output as an outbound text message with Twilio Programmable Messaging.<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight python"><code><span class="n">app</span> <span class="o">=</span> <span class="n">Flask</span><span class="p">(</span><span class="n">__name__</span><span class="p">)</span>


<span class="o">@</span><span class="n">app</span><span class="p">.</span><span class="n">route</span><span class="p">(</span><span class="s">"/sms"</span><span class="p">,</span> <span class="n">methods</span><span class="o">=</span><span class="p">[</span><span class="s">'GET'</span><span class="p">,</span> <span class="s">'POST'</span><span class="p">])</span>
<span class="k">def</span> <span class="nf">sms</span><span class="p">():</span>
    <span class="n">resp</span> <span class="o">=</span> <span class="n">MessagingResponse</span><span class="p">()</span>
    <span class="n">inb_msg</span> <span class="o">=</span> <span class="n">request</span><span class="p">.</span><span class="n">form</span><span class="p">[</span><span class="s">'Body'</span><span class="p">].</span><span class="n">lower</span><span class="p">().</span><span class="n">strip</span><span class="p">()</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">sms_chain</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">sms_input</span><span class="o">=</span><span class="n">inb_msg</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
    <span class="n">resp</span><span class="p">.</span><span class="n">message</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">str</span><span class="p">(</span><span class="n">resp</span><span class="p">)</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
    <span class="n">app</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">debug</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre>

</div>



<p>On the command line, run <code>python app.py</code> to start the Flask app.</p>

<h3>
  
  
  Configure a Twilio Number for the SMS Chatbot
</h3>

<p>Now, your Flask app will need to be visible from the web so Twilio can send requests to it. ngrok lets you do this. With ngrok installed, run <code>ngrok http 5000</code> in a new terminal tab in the directory your code is in.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--nsM06Uhj--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/2kgwrxcxdfgo9tkrp42o.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--nsM06Uhj--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/2kgwrxcxdfgo9tkrp42o.png" alt="ngrok terminal tab" width="800" height="334"></a><br>
You should see the screen above. Grab that ngrok <strong>Forwarding URL</strong> to configure your Twilio number: select your Twilio number under <strong>Active Numbers</strong> in your <a href="https://www.twilio.com/console/phone-numbers/incoming">Twilio console</a>, scroll to the <strong>Messaging</strong> section, and then modify the phone number‚Äôs routing by pasting the ngrok URL with the <em>/sms</em> path in the textbox corresponding to when <strong>A Message Comes In</strong> as shown below:</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--YFXGG5Ul--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/s6lgkzfqevilybi3al5s.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--YFXGG5Ul--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/s6lgkzfqevilybi3al5s.png" alt="configure phone number" width="800" height="335"></a><br>
Click <strong>Save</strong> and now your Twilio phone number is configured so that it maps to your web application server running locally on your computer and your application can run. Text your Twilio number a question relating to the text file and get an answer from that file over SMS!</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--NqUl4lle--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/3xi0flyo9fdgq4okmwgd.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--NqUl4lle--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/3xi0flyo9fdgq4okmwgd.png" alt="SMS example" width="800" height="226"></a><br>
You can view the <a href="https://github.com/elizabethsiegle/replicate-llama2-sms-chatbot">complete code on GitHub here</a>.</p>

<h3>
  
  
  What's Next for Twilio, LangChain, Replicate, and LLaMA 2?
</h3>

<p>There is so much fun for developers to have around building with LLMs! You can modify existing LangChain and LLM projects to use LLaMA 2 instead of GPT, build a web interface using <a href="https://streamlit.io/">Streamlit</a> instead of SMS, fine-tune LLaMA 2 with your own data, and more! I can't wait to see what you build‚Äìlet me know online what you're working on!</p>

<ul>
<li>Twitter: <a href="https://twitter.com/lizziepika">@lizziepika</a>
</li>
<li>GitHub: <a href="https://github.com/elizabethsiegle">elizabethsiegle</a>
</li>
<li>Email: <a href="mailto:lsiegle@twilio.com">lsiegle@twilio.com</a>
</li>
</ul>

 </details> 
 <hr /> 
<!-- BLOG-POST-LIST:END -->
</table>
</details>


<!-- TODO
Change the 3stats boxes around, possibly two on top and one on bottom
Fix RSSfeed
Fix Spotify Playlists
Fix Socials [Portfolio, Discord, Linkedin]
In the future, add Public Repositories of Selected Projects
-->
