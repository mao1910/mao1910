<!-- VISITOR BADGE -->
<!-- https://github.com/hehuapei/visitor-badge -->

<img align="right" src="https://visitor-badge.laobi.icu/badge?page_id=mao1910.mao1910&left_color=%2379DAF9&right_color=%23FE6E96" />


<!-- TYPING SVG -->
<!-- https://github.com/DenverCoder1/readme-typing-svg -->

<h1 align="center">
    <img src="https://readme-typing-svg.herokuapp.com/?font=Righteous&size=35&center=true&vCenter=true&width=500&height=70&color=FE6E96&font=poppins&duration=5000&lines=Hi+There!+üëã;+I'm+Mao!;" />
</h1>

<br/>

<!-- CODE/TERMINAL ABOUT ME -->
<h1 align="center">
<img src="./assets/terminal-5.gif" alt="Terminal" />
</h1>

<br/><br/><br/>


<!-- TECHNOLOGIES LOGOS -->
<!-- https://github.com/tandpfun/skill-icons -->

<h2 align="center">üíª Languages / Frameworks / Tools ‚öíÔ∏è</h2>
<div align="center">
    <img src="https://skillicons.dev/icons?i=javascript,typescript,angular,react,html,css,scss,bootstrap,cs,java,spring" />
    <img src="https://skillicons.dev/icons?i=flutter,firebase,supabase,mysql,git,github,gitlab,vscode,idea,maven,figma" />
</div>

<br/><br/><br/>


<!-- CONTRIBUTIONS SNAKE GAME -->
<!-- https://github.com/Platane/snk -->

<div align="center">
  <h2> My Contributionssssüêç </h2>
  <br>
  <img alt="contributions-eating Snake" src="https://raw.githubusercontent.com/mao1910/mao1910/output/github-contribution-grid-snake.svg" />

  <!-- Four lines below suggested by Planate for Dark mode-->
  <picture>
  <source media="(prefers-color-scheme: dark)" srcset="github-snake-dark.svg" />
  <source media="(prefers-color-scheme: light)" srcset="github-snake.svg" />
  </picture>
  
  <br/><br/><br/>
</div>


<!-- GITHUB STATS -->
<!-- https://github.com/DenverCoder1/github-readme-streak-stats -->
<!-- https://github.com/anuraghazra/github-readme-stats -->
<!-- https://github-readme-stats-mao1910.vercel.app/ My own Vercel deployment-->

<h2 align="center"> Statsüìù </h2>
  <br>
<div align=center>
  <img width=429 src="https://github-readme-stats-mao1910.vercel.app/api?username=mao1910&count_private=true&show_icons=true&theme=dracula&rank_icon=github&hide=contribs&border_radius=10&border_color=79DAF9" alt="github stats"/>
  <img width=396 src="https://streak-stats.demolab.com/?user=mao1910&count_private=true&theme=dracula&currStreakNum=79DAF9&currStreakLabel=FE6E96&border_radius=10&border=79DAF9" alt="streak stats"/>
  <br/>
  <img src="https://github-readme-stats-mao1910.vercel.app/api/top-langs/?username=mao1910&layout=compact&theme=dracula&border_radius=10&size_weight=0.5&count_weight=0.5&border_color=79DAF9" alt="languages stats" />
</div>

<br/><br/><br/>


<!-- FOOTER -->
<!-- https://github.com/DenverCoder1/readme-typing-svg -->
<!-- https://readme-typing-svg.demolab.com/demo/ -->

<a href="https://git.io/typing-svg"><img src="https://readme-typing-svg.demolab.com?font=Poppins&pause=1000&color=FE6E96&width=535&lines=Thanks+for+dropping+by!;Feel+free+to+check+any+of+the+Socials+below+%F0%9F%91%87;Or+the+Joke+Of+The+Day+if+you're+down+for+a+giggle+%F0%9F%98%9D;Hope+to+see+you+again+%F0%9F%91%8A;Uh%3F+You're+still+here%3F;Well...+I'm+running+out+of+things+to+say...;Tell+you+what%2C+due+to+your+effort+and+perseverance%2C;I+shall+present+you+with+a+short+poem%3A;%22To+code%2C+or+not+to+code%2C+that+is+the+question%3A;Whether+'tis+nobler+in+the+IDE+to+debug;The+errors+and+issues+of+outrageous+software%2C;Or+to+take+up+the+keyboard+against+a+sea+of+bugs;And+by+coding%2C+end+them.%22;by+William+Shakespeare%2C+probably.+;Pretty+sure+that's+Hamlet's.;Alrighty%2C+this+has+been+fun.;But+I'll+restart+the+loop+now...+see+ya+soon!" alt="Typing SVG" /></a>


<!--  SOCIAL NETWORKS -->
<!-- https://github.com/alexandresanlim/Badges4-README.md-Profile -->

  <div> 
    <a href="https://www.linkedin.com/" target="_blank"><img src="https://img.shields.io/badge/-LinkedIn-%230077B5?style=for-the-badge&logo=linkedin&logoColor=white" target="_blank"></a> <!-- ADD LINKEDIN PROFILE -->
    <a href = "https://www.google.com"><img src="https://img.shields.io/badge/Portfolio-4285F4?style=for-the-badge&logo=Google-chrome&logoColor=white" target="_blank"></a> <!-- ADD PORTFOLIO WEBSITE -->
    <a href="https://discord.gg" target="_blank"><img src="https://img.shields.io/badge/Discord-7289DA?style=for-the-badge&logo=discord&logoColor=white" target="_blank"></a> <!-- ADD DISCORD -->
    <a href = "mao1910dev@gmail.com"><img src="https://img.shields.io/badge/Gmail-D14836?style=for-the-badge&logo=gmail&logoColor=white" target="_blank"></a>
  </div>


<!-- SPOTIFY PLAYING-->
<!-- https://github.com/novatorem/novatorem -->
<!-- https://spotify-now-playing-novatorem-git-main-mao1910.vercel.app/ My own Vercel deployment-->

[<img width=438px src="https://spotify-now-playing-git-main-mao1910.vercel.app//api/spotify/?border_color=FE6E96" alt="Mao Spotify Now Playing" />](https://open.spotify.com/user/31542et242zglhf42ydrtqgvuvde)


<!-- JOKE OF THE DAY -->
<!-- https://github.com/ABSphreak/readme-jokes -->
<!-- https://readme-jokes-git-master-mao1910.vercel.app/ My own Vercel deployment-->

<details>
<summary>I've got a Joke for you. Wanna hear it? üôà</summary>

<br/>

 <tr>
 <td style="padding-top:4px"><img src = "https://readme-jokes-git-master-mao1910.vercel.app/api?&theme=dracula"></td>
 </tr>

</details>


<!-- ACTIVITY -->
<!-- https://github.com/jamesgeorge007/github-activity-readme -->


<details>
<summary>‚úçÔ∏è Activity</summary>

<br/>
<!-- START_SECTION:activity -->
<!--END_SECTION:activity-->

</details>


<!-- RSS FEED -->
<!-- https://github.com/gautamkrishnar/blog-post-workflow -->


<details>
<summary>üìï &nbsp;RSS feed</summary>

<br/>

<!-- BLOG-POST-LIST:START -->
 #### - [Generating Thumbnails from Videos using ApyHub‚Äôs API](https://dev.to/apyhub/generating-thumbnails-from-videos-using-apyhubs-api-p3k) 
 <details><summary>Article</summary> <p>As we have discussed in <a href="https://apyhub.com/blog/video-thumbnails-for-seo">previous articles</a>, video thumbnails have a lot of benefits and possible uses, including:</p>

<p>enhanced visual appeal, improved user experience, and of course a boost in brand identity and recognition. In this tutorial, we will go a bit more technical - focusing on the <a href="https://apyhub.com/utility/video-thumbnail">ApyHub video thumbnail</a> generator API.</p>

<p>No worries, this will be extremely simple and detailed. We will go slow and step by step, guiding you through every little detail. We will cover the API's core functionalities, including how to request thumbnails from videos using simple HTTP requests.</p>

<p>Moreover, we will show something cool: How to customize thumbnail dimensions and extract thumbnails from various time points within a video. Finally we will show how to seamlessly implement the generated thumbnails into your applications or websites</p>

<p>First things first - We'll start by importing packages and walk you through the process to execute the file using the Node.js command.</p>

<h3>
  
  
  <strong>Step 1: Set up the project</strong>
</h3>

<p>Create a new directory for your project and navigate to it using the terminal<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight jsx"><code><span class="nx">mkdir</span> <span class="nx">video</span><span class="o">-</span><span class="nx">thumbnail</span><span class="o">-</span><span class="nx">api</span><span class="o">-</span><span class="nx">nodejs</span>
<span class="nx">cd</span> <span class="nx">video</span><span class="o">-</span><span class="nx">thumbnail</span><span class="o">-</span><span class="nx">api</span><span class="o">-</span><span class="nx">nodejs</span>
</code></pre>

</div>



<h3>
  
  
  Step 2: Initialize Node.js Project
</h3>

<p>Initialize a Node.js project by running the following command. This will create a package.json file.<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight jsx"><code><span class="nx">npm</span> <span class="nx">init</span> <span class="o">-</span><span class="nx">y</span>
</code></pre>

</div>



<h3>
  
  
  Step 3: Install Required Packages
</h3>

<p>Install the required packages: Axios for making HTTP requests and form-data for handling multipart/form-data.<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight jsx"><code><span class="nx">npm</span> <span class="nx">install</span> <span class="nx">axios</span> <span class="nx">form</span><span class="o">-</span><span class="nx">data</span> <span class="nx">fs</span>
</code></pre>

</div>



<p>Once we run <code>npm install</code> in the terminal, the command triggers the installation of the specified dependencies listed in the project's package.json file. The following dependencies are commonly installed.</p>

<p><strong>axios:</strong> A popular HTTP client library for making HTTP requests in Node.js. It simplifies the process of sending HTTP requests and handling responses. In this case, axios is used to make a POST request to the Video Watermarking API, sending the video URL and watermark image URL.</p>

<p><strong>form-data:</strong> form-data is a JavaScript library that provides a way to create and handle multipart/form-data requests. It allows you to easily construct and send HTTP requests that contain files or other binary data. This library is often used in conjunction with axios or other HTTP client libraries to send form-based requests with files attached.</p>

<p><strong>fs (File System)</strong>: A built-in module in Node.js that provides functionalities for working with the file system. In this context, fs is used to create a write stream and save the watermarked video file. The createWriteStream function allows you to write the response data from the API request directly to a file on the local file system.</p>

<h3>
  
  
  Step 4: Create Your Integration Script
</h3>

<p>Create a file named <strong>generateThumbnail.js</strong> in your project directory.<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight jsx"><code><span class="c1">// Import required packages</span>
<span class="kd">const</span> <span class="nx">axios</span> <span class="o">=</span> <span class="nx">require</span><span class="p">(</span><span class="dl">'</span><span class="s1">axios</span><span class="dl">'</span><span class="p">);</span>
<span class="kd">const</span> <span class="nx">FormData</span> <span class="o">=</span> <span class="nx">require</span><span class="p">(</span><span class="dl">'</span><span class="s1">form-data</span><span class="dl">'</span><span class="p">);</span>
<span class="kd">const</span> <span class="nx">fs</span> <span class="o">=</span> <span class="nx">require</span><span class="p">(</span><span class="dl">'</span><span class="s1">fs</span><span class="dl">'</span><span class="p">);</span>

<span class="c1">// API endpoint URL</span>
<span class="kd">const</span> <span class="nx">apiUrl</span> <span class="o">=</span> <span class="dl">'</span><span class="s1">https://api.apyhub.com/generate/video-thumbnail/file</span><span class="dl">'</span><span class="p">;</span>

<span class="c1">// Replace 'YOUR_APY_TOKEN' with your actual API token</span>
<span class="kd">const</span> <span class="nx">apyToken</span> <span class="o">=</span> <span class="dl">'</span><span class="s1">YOUR_APY_TOKEN</span><span class="dl">'</span><span class="p">;</span>

<span class="c1">// Define the file path and details</span>
<span class="kd">const</span> <span class="nx">videoFilePath</span> <span class="o">=</span> <span class="dl">'</span><span class="s1">/path_to_file</span><span class="dl">'</span><span class="p">;</span>
<span class="kd">const</span> <span class="nx">outputFileName</span> <span class="o">=</span> <span class="dl">'</span><span class="s1">PROVIDE_THE_OUTPUT_FILE_NAME</span><span class="dl">'</span><span class="p">;</span>
<span class="kd">const</span> <span class="nx">startTime</span> <span class="o">=</span> <span class="dl">'</span><span class="s1">0</span><span class="dl">'</span><span class="p">;</span>
<span class="kd">const</span> <span class="nx">duration</span> <span class="o">=</span> <span class="dl">'</span><span class="s1">2</span><span class="dl">'</span><span class="p">;</span>
<span class="kd">const</span> <span class="nx">size</span> <span class="o">=</span> <span class="dl">'</span><span class="s1">400x300</span><span class="dl">'</span><span class="p">;</span>

<span class="k">async</span> <span class="kd">function</span> <span class="nx">generateThumbnail</span><span class="p">()</span> <span class="p">{</span>
  <span class="k">try</span> <span class="p">{</span>
    <span class="c1">// Create form data</span>
    <span class="kd">const</span> <span class="nx">form</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">FormData</span><span class="p">();</span>
    <span class="nx">form</span><span class="p">.</span><span class="nx">append</span><span class="p">(</span><span class="dl">'</span><span class="s1">video</span><span class="dl">'</span><span class="p">,</span> <span class="nx">fs</span><span class="p">.</span><span class="nx">createReadStream</span><span class="p">(</span><span class="nx">videoFilePath</span><span class="p">));</span>
    <span class="nx">form</span><span class="p">.</span><span class="nx">append</span><span class="p">(</span><span class="dl">'</span><span class="s1">start_time</span><span class="dl">'</span><span class="p">,</span> <span class="nx">startTime</span><span class="p">);</span>
    <span class="nx">form</span><span class="p">.</span><span class="nx">append</span><span class="p">(</span><span class="dl">'</span><span class="s1">duration</span><span class="dl">'</span><span class="p">,</span> <span class="nx">duration</span><span class="p">);</span>
    <span class="nx">form</span><span class="p">.</span><span class="nx">append</span><span class="p">(</span><span class="dl">'</span><span class="s1">size</span><span class="dl">'</span><span class="p">,</span> <span class="nx">size</span><span class="p">);</span>

    <span class="c1">// Set headers</span>
    <span class="nx">form</span><span class="p">.</span><span class="nx">append</span><span class="p">(</span><span class="dl">'</span><span class="s1">apy-token</span><span class="dl">'</span><span class="p">,</span> <span class="nx">apiToken</span><span class="p">);</span>

    <span class="c1">// Make POST request</span>
    <span class="kd">const</span> <span class="nx">response</span> <span class="o">=</span> <span class="k">await</span> <span class="nx">axios</span><span class="p">.</span><span class="nx">post</span><span class="p">(</span><span class="nx">apiUrl</span><span class="p">,</span> <span class="nx">form</span><span class="p">,</span> <span class="p">{</span>
      <span class="na">headers</span><span class="p">:</span> <span class="p">{</span>
        <span class="nx">form</span><span class="p">.</span><span class="nx">getHeaders</span><span class="p">(),</span>
      <span class="p">},</span>
      <span class="na">params</span><span class="p">:</span> <span class="p">{</span>
        <span class="na">output</span><span class="p">:</span> <span class="nx">outputFileName</span><span class="p">,</span>
      <span class="p">},</span>
    <span class="p">});</span>

    <span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="dl">'</span><span class="s1">Thumbnail generation response:</span><span class="dl">'</span><span class="p">,</span> <span class="nx">response</span><span class="p">.</span><span class="nx">data</span><span class="p">);</span>
  <span class="p">}</span> <span class="k">catch</span> <span class="p">(</span><span class="nx">error</span><span class="p">)</span> <span class="p">{</span>
    <span class="nx">console</span><span class="p">.</span><span class="nx">error</span><span class="p">(</span><span class="dl">'</span><span class="s1">Error generating thumbnail:</span><span class="dl">'</span><span class="p">,</span> <span class="nx">error</span><span class="p">.</span><span class="nx">message</span><span class="p">);</span>
  <span class="p">}</span>
<span class="p">}</span>

<span class="c1">// Call the function to generate the thumbnail</span>
<span class="nx">generateThumbnail</span><span class="p">();</span>
</code></pre>

</div>



<p><strong>Step 5: Execute the Script</strong></p>

<p>Execute the script using the Node.js command.<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight jsx"><code><span class="nx">node</span> <span class="nx">generateThumbnail</span><span class="p">.</span><span class="nx">js</span>
</code></pre>

</div>



<p>That's it! It wasn't so difficult right? We have now successfully integrated the <a href="https://apyhub.com/utility/video-thumbnail">Video Thumbnail API</a> using Node.js!</p>

<p>Using this service, we can generate video thumbnails from literally any part of a video file or URL (e.g. youtube). This way, we automate extracting thumbnails from videos , allowing for efficient and consistent extraction of thumbnails without the need of any manual work. This can save both time and resources for all businesses and content creators. </p>

<p>The <a href="https://apyhub.com/utility/video-thumbnail">ApyHub Video Thumbnail API</a> can also be integrated into existing workflows and platforms, making it easy to incorporate thumbnail extraction into existing processes.<br>
Good luck with using the API. Looking forward to any feedback on <a href="https://discord.gg/KcjnPHef7p">discord</a>.</p>

 </details> 
 <hr /> 

 #### - [Power Automate - Flow Logging in App Insights](https://dev.to/wyattdave/power-automate-flow-logging-in-app-insights-lp) 
 <details><summary>Article</summary> <p>One of the big challenges with maintaining production flows in Power Automate was the lack of read only access. This meant to read a flow log you would need full edit access, not good for production environments using Service Accounts.</p>

<p>Fortunately Microsoft heard us and just launch <a href="https://learn.microsoft.com/en-us/power-platform/admin/app-insights-cloud-flow">flow log integration with Application Insights</a>. App Insights is the Azure standard for all logging, so it's incredibly powerful, additionally it can be setup with notification alerts and used as a data source for Power BI dashboards. It's not free (small memory cost and for alerts) and requires someone with Azure experience and permissions to create one.</p>

<p>Couple of call outs:</p>

<ul>
<li>It's not the same as the logs, as you do not see in flow data (the inputs and outputs, just the actions)</li>
<li>The Global Power Platform Admin who creates the connection requires edit access to the app insight instance</li>
<li>Each connection is between one environment and one app, but you can create multiple connections to each app, so you could have all your production flows linked to one App, all Dev another. Likewise you could link one environment to 2 apps, one for all Prod, one for the particular Dev,Test,Prod stack.</li>
<li>In preview it works on any environment, once out of preview it will only work on Managed Environments (no surprise there lol)</li>
</ul>

<h2>
  
  
  Setup
</h2>

<p>Setup is nice and easy, you need to be a Global Power Platform Admin, then you select following menus:<br>
<strong>Analytics - Data Export - App Insights - New Data Export</strong></p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--q4iqS0aC--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/7s9sjxxe9cr728auuky7.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--q4iqS0aC--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/7s9sjxxe9cr728auuky7.png" alt="app insight config 1" width="800" height="417"></a><br>
Select Power Automate and runs, triggers, actions</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--1jf-PMs---/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/0v45xhw85al4v6fosblv.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--1jf-PMs---/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/0v45xhw85al4v6fosblv.png" alt="select environment" width="800" height="455"></a><br>
Select required environment</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--qYAhrFkc--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/oddufxop5koiqll5hbup.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--qYAhrFkc--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/oddufxop5koiqll5hbup.png" alt="select app insights" width="800" height="454"></a><br>
Select subscription, resource group, from there you should see the list of available App Insights, select the required one</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--cU_87BKc--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/aqi84jhzw8208zrnaab4.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--cU_87BKc--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/aqi84jhzw8208zrnaab4.png" alt="app insight connections" width="800" height="373"></a></p>

<p>You should then see list of all your connections, you can add more with the new data export from the top.</p>
<h2>
  
  
  App Insights
</h2>

<p>App Insights can be found in your Azure Portal</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--sp7yNqN0--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/vvy64f5u7hydz1mxtf5u.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--sp7yNqN0--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/vvy64f5u7hydz1mxtf5u.png" alt="app insights" width="612" height="298"></a></p>

<p>There is so much you can do with App Insights, like live data, alerts, and more. But I'm just going to look at the log query, as this is in my opinion the most useful.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--xWhX1DZi--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/zaovm4iqaxjdtdnwmohz.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--xWhX1DZi--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/zaovm4iqaxjdtdnwmohz.png" alt="app insight query" width="800" height="469"></a></p>

<p>There are couple key commands that I use:</p>

<p><code>let</code>- for variables <code>let myEnvironmentId = 'ca99eaab-99a9-ef99-9b99-99ded999999f';</code></p>

<p><code>requests</code> <code>dependencies</code> <code>traces</code> <code>exceptions</code> <code>customMetrics</code> - the table for what log you need, for Flows we just use requests and dependencies</p>

<p><code>| where</code> - standard filter the results by <code>| where customDimensions ['environmentId'] == myEnvironmentId</code></p>

<p><code>| extend</code> - brings nested keys/fields to the root <code>| extend Data = todynamic(tostring(customDimensions.Data))</code></p>

<p><code>| project</code> - selects required keys/fields for the report <code>| project timestamp ,id ,DisplayName = Data.FlowDisplayName</code></p>
<h2>
  
  
  Request and Dependency Structure
</h2>

<p>There are a lot of keys/fields returned from the 2 tables, but to keep it simple I will identify the key ones:</p>

<p><strong>Requests</strong></p>

<div class="table-wrapper-paragraph"><table>
<thead>
<tr>
<th>Key/Field            Ôªø</th>
<th>Description</th>
<th>Node</th>
</tr>
</thead>
<tbody>
<tr>
<td>timestamp</td>
<td>date / time of run</td>
<td></td>
</tr>
<tr>
<td>id</td>
<td>GUID for app insights</td>
<td></td>
</tr>
<tr>
<td>success</td>
<td>boolean if run was successful</td>
<td></td>
</tr>
<tr>
<td>name</td>
<td>flow id</td>
<td></td>
</tr>
<tr>
<td>duration</td>
<td>time for flow to complete</td>
<td></td>
</tr>
<tr>
<td>itemType</td>
<td>request or dependency</td>
<td></td>
</tr>
<tr>
<td>customDimensions</td>
<td>main node of data</td>
<td></td>
</tr>
<tr>
<td>Data</td>
<td>node of data</td>
<td>customDimensions</td>
</tr>
<tr>
<td>FlowDisplayName</td>
<td>flow name</td>
<td>Data</td>
</tr>
<tr>
<td>RunId</td>
<td>Run ID</td>
<td>Data</td>
</tr>
<tr>
<td>tags</td>
<td>node of data</td>
<td>Data</td>
</tr>
<tr>
<td>createdBy</td>
<td>flow owner id</td>
<td>tags</td>
</tr>
<tr>
<td>environmentId</td>
<td>environment id</td>
<td>customDimensions</td>
</tr>
<tr>
<td>error</td>
<td>node of data</td>
<td>customDimensions</td>
</tr>
<tr>
<td>code</td>
<td>error description</td>
<td>error</td>
</tr>
<tr>
<td>message</td>
<td>error reason</td>
<td>error</td>
</tr>
<tr>
<td>signalCategory</td>
<td>log type (cloud/desktop)</td>
<td>customDimensions</td>
</tr>
</tbody>
</table></div>

<p><strong>Dependencies</strong></p>

<div class="table-wrapper-paragraph"><table>
<thead>
<tr>
<th>Key/FieldÔªø</th>
<th>Description</th>
<th>Node</th>
</tr>
</thead>
<tbody>
<tr>
<td>timestamp</td>
<td>date / time of run</td>
<td></td>
</tr>
<tr>
<td>id</td>
<td>GUID for app insights</td>
<td></td>
</tr>
<tr>
<td>resourceId</td>
<td>Flow ID</td>
<td>customDimensions</td>
</tr>
<tr>
<td>success</td>
<td>boolean if action was successful</td>
<td></td>
</tr>
<tr>
<td>name</td>
<td>action name</td>
<td></td>
</tr>
<tr>
<td>duration</td>
<td>time for flow to complete</td>
<td></td>
</tr>
<tr>
<td>itemType</td>
<td>request or dependency</td>
<td></td>
</tr>
<tr>
<td>RunId</td>
<td>Run ID</td>
<td>Data</td>
</tr>
<tr>
<td>customDimensions</td>
<td>main node of data</td>
<td></td>
</tr>
<tr>
<td>Data</td>
<td>node of data</td>
<td>customDimensions</td>
</tr>
<tr>
<td>FlowDisplayName</td>
<td>flow name</td>
<td>Data</td>
</tr>
<tr>
<td>operation_ParentId</td>
<td>Run ID</td>
<td>Data</td>
</tr>
<tr>
<td>actionType</td>
<td>action type</td>
<td>Data</td>
</tr>
<tr>
<td>tags</td>
<td>node of data</td>
<td>Data</td>
</tr>
<tr>
<td>createdBy</td>
<td>flow owner id</td>
<td>tags</td>
</tr>
<tr>
<td>environmentId</td>
<td>environment id</td>
<td>customDimensions</td>
</tr>
<tr>
<td>error</td>
<td>node of data</td>
<td>customDimensions</td>
</tr>
<tr>
<td>code</td>
<td>error description</td>
<td>error</td>
</tr>
<tr>
<td>message</td>
<td>error reason</td>
<td>error</td>
</tr>
<tr>
<td>signalCategory</td>
<td>log type (cloud/desktop)</td>
<td>customDimensions</td>
</tr>
</tbody>
</table></div>

<p><strong>Relationships</strong></p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--AdyWaEdf--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/nefgbdx9okyqluscli45.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--AdyWaEdf--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/nefgbdx9okyqluscli45.png" alt="request to dependency relationships" width="800" height="497"></a></p>
<h2>
  
  
  Queries
</h2>

<p>You can see there are infinite different queries you can run, but I thought I would show the 3 that I have started to use:</p>

<p><strong>Flow Runs</strong><br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>let myEnvironmentId = 'ca84eccb-78a7-ef84-9b20-84ded785680f'; 
requests 
| where customDimensions ['resourceProvider'] == 'Cloud Flow' 
| where customDimensions ['signalCategory'] == 'Cloud flow runs' 
| where customDimensions ['environmentId'] == myEnvironmentId 
| extend Data = todynamic(tostring(customDimensions.Data)) 
| extend Error = todynamic(tostring(customDimensions.error)) 
| project timestamp 
,id 
,DisplayName = Data.FlowDisplayName
,name
,RunID = Data.OriginRunId  
,ErrorCode = Error.code  
,ErrorMessage = Error.message  
,success 
,customDimensions
</code></pre>

</div>



<p>This query brings up all my flow runs (I use the time range in App Insights to narrow down time range). I also add <code>| where success== False</code> when I want just failed runs.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--OgO0UcgO--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/nt9r1mfb7dg8cj46uzeq.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--OgO0UcgO--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/nt9r1mfb7dg8cj46uzeq.png" alt="flow runs results" width="800" height="149"></a></p>

<p><strong>Flow Action Performance</strong><br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>let myEnvironmentId = 'ca99eaab-99a9-ef99-9b99-99ded999999f'; 
let myFlowId = '90911457-7dd5-453b-afb3-8f8f3374c599'; 
dependencies
| extend Data = todynamic(tostring(customDimensions.Data)) 
| extend DisplayName = Data.FlowDisplayName 
| extend RunID = Data.OriginRunId 
| extend Error = todynamic(tostring(customDimensions.error)) 
| extend ErrorCode = Error.code 
| extend ErrorMessage = Error.message 
| where name == 'Fail'
| where customDimensions.resourceId == myFlowId
| where customDimensions ['environmentId'] == myEnvironmentId 
| project timestamp 
,id 
,DisplayName 
,name
,operation_ParentId 
,ErrorCode
,ErrorMessage 
,success 
,customDimensions
</code></pre>

</div>



<p>This query allows me to look at how a specific action has performed over a set time span, helping debug potential issues.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--Yco1hQt8--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/vx841ca7i02wvmyj6ehl.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--Yco1hQt8--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/vx841ca7i02wvmyj6ehl.png" alt="flow action results" width="800" height="106"></a></p>

<p><strong>Flow Detail</strong><br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>let myEnvironmentId = 'ca99eaab-99a9-ef99-9b99-99ded999999f'; 
let myEnvironmentId = 'ca84eccb-78a7-ef84-9b20-84ded785680f'; 
let queryId='08585075362661487682209269813CU165'; 
(requests |union dependencies) 
| extend Data = todynamic(tostring(customDimensions.Data)) 
| extend DisplayName = Data.FlowDisplayName 
| extend RunID = Data.OriginRunId 
| extend Error = todynamic(tostring(customDimensions.error)) 
| extend ErrorCode = Error.code 
| extend ErrorMessage = Error.message 
| where operation_ParentId == queryId or RunID == queryId 
| where customDimensions ['environmentId'] == myEnvironmentId 
| project timestamp 
,id 
,DisplayName 
,name
,RunID 
,operation_ParentId 
,ErrorCode
,ErrorMessage 
,success 
,customDimensions
</code></pre>

</div>



<p>The above query allows me to view a specific flow run, with the request and dependencies union'd together.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--54Kz8_ie--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/u1rlgzcgxdn10e70p3uc.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--54Kz8_ie--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/u1rlgzcgxdn10e70p3uc.png" alt="flow run results" width="800" height="146"></a></p>

<h2>
  
  
  What's Next
</h2>

<p>So this is a good starting point to track flow performance and identify failed runs. But what is really cool is you can easily add the App Insights data to Power BI:</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--i6Y9g6PY--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ytqju7po2ggcb0sscmap.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--i6Y9g6PY--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ytqju7po2ggcb0sscmap.png" alt="app insights export" width="251" height="217"></a></p>

<p>Just click new dataset and it will open Power BI and create the connection and allow you to create reports with live data.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--QYLi6FcZ--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/orid5at4qkwijq56kj51.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--QYLi6FcZ--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/orid5at4qkwijq56kj51.png" alt="power bi data connection" width="800" height="488"></a><br>
Below is auto generated, so you can do a lot more with some effort.<br>
<a href="https://res.cloudinary.com/practicaldev/image/fetch/s--a8RggktY--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/j8cxyibo9otszdicq8vk.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--a8RggktY--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/j8cxyibo9otszdicq8vk.png" alt="power bi report" width="800" height="405"></a></p>

 </details> 
 <hr /> 

 #### - [Sentiment Analysis Using Python: A Beginner-Friendly Tutorial!](https://dev.to/pavanbelagatti/sentiment-analysis-using-python-a-beginner-friendly-tutorial-34da) 
 <details><summary>Article</summary> <p>If you've ever wondered how companies understand customer opinions, or how social media platforms gauge public sentiment, you're in the right place. Sentiment Analysis is a fascinating field at the intersection of data science and natural language processing, and Python is one of the most popular languages to perform this analysis. Whether you're completely new to Python or just new to the world of Sentiment Analysis, this tutorial is designed with you in mind. </p>

<h2>
  
  
  What is Sentiment Analysis?
</h2>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--UVfpnM_L--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ef1rsw5ab2r96bod5qqp.jpg" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--UVfpnM_L--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ef1rsw5ab2r96bod5qqp.jpg" alt="Sentiment Analysis" width="800" height="314"></a></p>

<p>Sentiment Analysis, also known as opinion mining, is the process of using natural language processing, text analysis, and computational linguistics to identify and categorize subjective opinions or feelings expressed in a piece of text. The primary objective is to determine the writer's attitude toward a particular topic, product, or service as positive, negative, or neutral. In some advanced forms, sentiment analysis may also involve identifying the intensity of the sentiment or even categorizing it into more specific emotional states like "happy," "angry," or "sad."</p>

<p>Let's understand sentiment analysis with a simple hands-on tutorial. We will use SingleStore's Notebooks feature in this tutorial. So <strong>let's get started!</strong></p>

<h2>
  
  
  Prerequisites
</h2>

<ul>
<li><a href="https://www.python.org/downloads/">Python installed</a></li>
<li>
<a href="https://www.singlestore.com/cloud-trial/?utm_medium=referral&amp;utm_source=pavan&amp;utm_term=devto&amp;utm_content=sentimentanalysis">SingleStore Notebook installed</a>. Signup and select SingleStore Notebooks feature</li>
<li>Install required Python package: textblob</li>
</ul>

<p>You can install TextBlob using pip:<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>pip install textblob
</code></pre>

</div>

<h2>
  
  
  Steps to Create the SingleStore Notebook
</h2>

<p>We will use SingleStore's Notebooks feature (it is FREE to use) as our development environment for this tutorial.</p>

<p>The SingleStore Notebook extends the capabilities of Jupyter Notebook to enable data professionals to easily work and play around. </p>
<h4>
  
  
  What is SingleStore?
</h4>

<p><a href="https://www.singlestore.com/cloud-trial/?utm_medium=referral&amp;utm_source=pavan&amp;utm_term=devto&amp;utm_content=sentimentanalysis">SingleStore</a> is a distributed, in-memory, SQL database management system designed for high-performance, high-velocity applications. It offers real-time analytics and mixes the capabilities of a traditional operational database with that of an analytical database to allow for transactions and analytics to be performed in a single system.</p>

<p>Signup for <a href="https://www.singlestore.com/cloud-trial/?utm_medium=referral&amp;utm_source=pavan&amp;utm_term=devto&amp;utm_content=sentimentanalysis">SingleStore</a> to use the Notebooks.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--S25EcECw--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ug1scnnwrz9ar1op5yji.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--S25EcECw--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ug1scnnwrz9ar1op5yji.png" alt="SingleStore Notebooks feature" width="592" height="832"></a></p>

<p>Once you sign up to SingleStore, you will also receive $600 worth free computing resources. So why not use this opportunity.</p>

<p>Click on 'Notebooks' and start with a blank Notebook.<br>
<a href="https://res.cloudinary.com/practicaldev/image/fetch/s--EwcKnmfM--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/99l9xf5hltflrjbl8qlx.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--EwcKnmfM--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/99l9xf5hltflrjbl8qlx.png" alt="singlestore notebooks usage" width="800" height="961"></a></p>

<p>Name it something like 'Sentiment-Tutorial' or as per your wish.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--NvkD06D1--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/wk3s4wcsgl5tw3alfxa9.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--NvkD06D1--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/wk3s4wcsgl5tw3alfxa9.png" alt="blank notebook" width="800" height="546"></a></p>

<p>Let's start working with our Notebook that we just created.<br>
Follow this step by step guide and keep adding the code shown in each step in your Notebook and execute it. Let's start!</p>
<h4>
  
  
  Step 1: Import Libraries
</h4>


<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>from textblob import TextBlob
</code></pre>

</div>

<h4>
  
  
  Step 2: Define Sample Text Data
</h4>

<p>We'll use a list of sample sentences for this example.<br>
</p>
<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>sample_texts = [
    "I love programming.",
    "I hate bugs.",
    "I feel indifferent about documentation.",
    "Debugging is fun!",
    "I'm frustrated with errors."
]

</code></pre>

</div>

<h4>
  
  
  Step 3: Analyze Sentiment
</h4>

<p>We'll loop through the sample texts and analyze their sentiment using TextBlob.<br>
</p>
<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>for text in sample_texts:
    analysis = TextBlob(text)
    polarity = analysis.sentiment.polarity
    subjectivity = analysis.sentiment.subjectivity

    if polarity &gt; 0:
        sentiment = "Positive"
    elif polarity &lt; 0:
        sentiment = "Negative"
    else:
        sentiment = "Neutral"

    print(f"Text: {text}")
    print(f"Sentiment: {sentiment}")
    print(f"Polarity: {polarity}")
    print(f"Subjectivity: {subjectivity}")
    print("------")
</code></pre>

</div>


<p>This will output the sentiment, polarity, and subjectivity for each sample sentence.</p>
<h4>
  
  
  Step 4: Interpret Results
</h4>

<ul>
<li><p><strong>Polarity</strong>: Ranges from -1 to 1. Negative value indicates negative sentiment, and a positive value indicates positive sentiment.</p></li>
<li><p><strong>Subjectivity</strong>: Ranges from 0 to 1. Higher values indicate that the text contains personal opinion, emotion, or judgment.</p></li>
</ul>

<p>You can put all these code snippets together in a SingleStore Notebook to create a complete workflow for basic sentiment analysis.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--Ly1UrEqn--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/nz0tbg61gwtdywdefsbt.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--Ly1UrEqn--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/nz0tbg61gwtdywdefsbt.png" alt="ss notebooks usage" width="800" height="451"></a></p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--2llxUtcd--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/uvbsa50dxyuc3zk5v3z9.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--2llxUtcd--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/uvbsa50dxyuc3zk5v3z9.png" alt="sentiment analysis" width="798" height="1336"></a></p>

<p>The complete Notebook code is available here on my <a href="https://github.com/pavanbelagatti/sentiment-analysis">GitHub repository</a>. </p>

<p><em>Congratulations on completing 'Your First Sentiment Analysis Project in Python!</em> By now, you should have some understanding of the basics of Sentiment Analysis and how to implement it using Python and Notebooks. You've not only learned the theory but also applied it in a simple hands-on project. </p>

<p>As you continue your journey in data science, remember that Sentiment Analysis is just the tip of the iceberg. There are countless other exciting applications and techniques waiting for you to explore. So, what's next? Keep practicing, consider diving into more advanced topics like Large Language Models (LLMs), LangChain, Vector Databases, etc.</p>

<p>Take a look at my other articles that talk about the above important topics/concepts. </p>


<div class="ltag__link">
  <a href="/pavanbelagatti" class="ltag__link__link">
    <div class="ltag__link__pic">
      <img src="https://res.cloudinary.com/practicaldev/image/fetch/s--Zi879WGp--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://res.cloudinary.com/practicaldev/image/fetch/s--SzI-nAkL--/c_fill%2Cf_auto%2Cfl_progressive%2Ch_150%2Cq_auto%2Cw_150/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/68703/6b2032e7-c028-4024-b132-260b569d1989.jpeg" alt="pavanbelagatti">
    </div>
  </a>
  <a href="/pavanbelagatti/python-cheat-sheet-for-data-engineers-and-data-scientists-3emj" class="ltag__link__link">
    <div class="ltag__link__content">
      <h2>Python Cheat Sheet for Data Engineers and Data Scientists!</h2>
      <h3>Pavan Belagatti „Éª Aug 31</h3>
      <div class="ltag__link__taglist">
        <span class="ltag__link__tag">#python</span>
        <span class="ltag__link__tag">#datascience</span>
        <span class="ltag__link__tag">#dataengineering</span>
        <span class="ltag__link__tag">#developers</span>
      </div>
    </div>
  </a>
</div>




<div class="ltag__link">
  <a href="/pavanbelagatti" class="ltag__link__link">
    <div class="ltag__link__pic">
      <img src="https://res.cloudinary.com/practicaldev/image/fetch/s--Zi879WGp--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://res.cloudinary.com/practicaldev/image/fetch/s--SzI-nAkL--/c_fill%2Cf_auto%2Cfl_progressive%2Ch_150%2Cq_auto%2Cw_150/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/68703/6b2032e7-c028-4024-b132-260b569d1989.jpeg" alt="pavanbelagatti">
    </div>
  </a>
  <a href="/pavanbelagatti/a-beginners-guide-to-building-llm-powered-applications-with-langchain-2d6e" class="ltag__link__link">
    <div class="ltag__link__content">
      <h2>A Beginner‚Äôs Guide to Building LLM-Powered Applications with LangChain!</h2>
      <h3>Pavan Belagatti „Éª Aug 30</h3>
      <div class="ltag__link__taglist">
        <span class="ltag__link__tag">#datascience</span>
        <span class="ltag__link__tag">#dataengineering</span>
        <span class="ltag__link__tag">#llm</span>
        <span class="ltag__link__tag">#database</span>
      </div>
    </div>
  </a>
</div>



<div class="ltag__link">
  <a href="/pavanbelagatti" class="ltag__link__link">
    <div class="ltag__link__pic">
      <img src="https://res.cloudinary.com/practicaldev/image/fetch/s--Zi879WGp--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://res.cloudinary.com/practicaldev/image/fetch/s--SzI-nAkL--/c_fill%2Cf_auto%2Cfl_progressive%2Ch_150%2Cq_auto%2Cw_150/https://dev-to-uploads.s3.amazonaws.com/uploads/user/profile_image/68703/6b2032e7-c028-4024-b132-260b569d1989.jpeg" alt="pavanbelagatti">
    </div>
  </a>
  <a href="/pavanbelagatti/wtf-is-a-vector-database-a-beginners-guide-16p" class="ltag__link__link">
    <div class="ltag__link__content">
      <h2>WTF Is a Vector Database: A Beginner's Guide!</h2>
      <h3>Pavan Belagatti „Éª Aug 25</h3>
      <div class="ltag__link__taglist">
        <span class="ltag__link__tag">#database</span>
        <span class="ltag__link__tag">#ai</span>
        <span class="ltag__link__tag">#devops</span>
        <span class="ltag__link__tag">#developers</span>
      </div>
    </div>
  </a>
</div>


 </details> 
 <hr /> 

 #### - [AWS open source newsletter, #173](https://dev.to/aws/aws-open-source-newsletter-173-3bof) 
 <details><summary>Article</summary> <h2>
  
  
  September 11th, 2023 - Instalment #173
</h2>

<p>Welcome to #173 of the AWS open source newsletter, bringing you all the news and latest projects for AWS developers. This weeks new projects include a Golang based SDK for kernel eBPF operations, a project that helps you to optimise your network performance, a couple of projects for Apache Flink users, as well as a handful of different tools and demos featuring open source technologies helping to drive innovation in generative AI. !As well as the new projects, we also have content this week on open source technologies including ebpf, Apache Flink, Griptape, AWS Amplify, Amazon Corretto, Smithy, lakeFS, Jupyter, GitLab, OpenSearch, Apache Kafka, Apache Iceberg, OpenQAOA, AWS Toolkit for Visual Studio, Apache Airflow, PostgreSQL, MySQL, AWS SAM, PyTorch, and Flux. </p>

<p>Finally, be sure to check out the events section as there are a few events happening this week. Before you dive into the newsletter, check out the following information on open source mentorship program being sponsored by the OpenSearch project.</p>

<p><strong>Open Source Mentorship</strong></p>

<p>The OpenSearch group is going to be doing their second cohort of our open source mentorship program. This program helps new developers make contributions to open source software, giving them a portfolio to launch them into their career. This is a really exciting opportunity, so please make some time to read <a href="https://aws-oss.beachgeek.co.uk/38p">Receive mentorship from Amazon engineers and accelerate your career in Tech</a> where Iskander Rakhman talks about the history of the program, provides lots of details you will want to know, and provides a link where you can sign up. Please share with anyone you know who is looking for an opportunity like this to kick start their open source journey.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--3UiWUaZj--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://opensearch.org/assets/media/blog-images/2023-09-05-college-contributor-initiative/Hot%2520Air%2520Balloon.jpg" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--3UiWUaZj--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://opensearch.org/assets/media/blog-images/2023-09-05-college-contributor-initiative/Hot%2520Air%2520Balloon.jpg" alt="image of open source mentorship blog post" width="800" height="369"></a></p>

<p><strong>Feedback</strong></p>

<p>Before you dive in however, I need your help!  Please please please take 1 minute to <a href="https://www.pulse.aws/promotion/10NT4XZQ">complete this short survey</a> and you will forever have my gratitude! </p>

<h3>
  
  
  Celebrating open source contributors
</h3>

<p>The articles and projects shared in this newsletter are only possible thanks to the many contributors in open source. I would like to shout out and thank those folks who really do power open source and enable us all to learn and build on top of what they have created.</p>

<p>So thank you to the following open source heroes:  Jay Pillai, Shikhar Kwatra, Karthik Sonti,  Ken Collins, Supratip Banerjee, Nathan Peck, Lionel Tchami, Dr. Aparna Sundar, Will Childs-Klein, Andrew Foss, Vijay Karumajji, Eric Johnson, Rio Astamal,  Sukhpreet Bedi, Betty Zheng, and Iskander Rakhman</p>

<h3>
  
  
  Latest open source projects
</h3>

<p><em>The great thing about open source projects is that you can review the source code. If you like the look of these projects, make sure you that take a look at the code, and if it is useful to you, get in touch with the maintainer to provide feedback, suggestions or even submit a contribution. The projects mentioned here do not represent any formal recommendation or endorsement, I am just sharing for greater awareness as I think they look useful and interesting!</em></p>

<h4>
  
  
  Tools
</h4>

<p><strong>hypergraph-tabular-lm</strong></p>

<p><a href="https://aws-oss.beachgeek.co.uk/38l">hypergraph-tabular-lm</a> This repository contains the official implementation for the paper <a href="https://aws-oss.beachgeek.co.uk/38m">HyTrel: Hypergraph-enhanced Tabular Data Representation Learning</a> with code, data, and checkpoints. From the abstract we can see:</p>

<blockquote>
<p>Language models pretrained on large collections of tabular data have demonstrated their effectiveness in several downstream tasks. However, many of these models do not take into account the row/column permutation invariances, hierarchical structure, etc. that exist in tabular data. To alleviate these limitations, we propose HYTREL, a tabular language model, that captures the permutation invariances and three more structural properties of tabular data by using hypergraphs‚Äìwhere the table cells make up the nodes and the cells occurring jointly together in each row, column, and the entire table are used to form three different types of hyperedges.</p>
</blockquote>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--clyksqDQ--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://github.com/awslabs/hypergraph-tabular-lm/blob/main/figure1.png%3Fraw%3Dtrue" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--clyksqDQ--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://github.com/awslabs/hypergraph-tabular-lm/blob/main/figure1.png%3Fraw%3Dtrue" alt="diagram of hypergraph tabular lm" width="800" height="274"></a></p>

<p><strong>dpdk-setup-eks</strong></p>

<p><a href="https://aws-oss.beachgeek.co.uk/37x">dpdk-setup-eks</a> provides sample code on how you can use packet acceleration using SRIOV (Single Root I/O Virtualization) and DPDK (Data Plane Development Kit) to achieve high network bandwidth, maximum throughput, and minimal latency in your cloud native workloads. SRIOV enables hardware-based acceleration in a virtualised environment that provides higher I/O performance, lower CPU utilisation, higher packet per second (PPS) performance, and lower latency. DPDK provides software-based development kit, which bypasses the operating system (OS) kernel and reduces packet processing overhead, resulting in performance improvement and lower latency. To help you get started with this code, following along with the post <a href="https://aws-oss.beachgeek.co.uk/37y">Automate Packet Acceleration configuration using DPDK on Amazon EKS</a>.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--PX5z_z1---/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://d2908q01vomqb2.cloudfront.net/c5b76da3e608d34edb07244cd9b875ee86906328/2023/08/30/Create-EKS-Nodegroup-with-the-pre-built-DPDK-AMI-1024x612.jpg" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--PX5z_z1---/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://d2908q01vomqb2.cloudfront.net/c5b76da3e608d34edb07244cd9b875ee86906328/2023/08/30/Create-EKS-Nodegroup-with-the-pre-built-DPDK-AMI-1024x612.jpg" alt="overview of high performance networking on eks" width="800" height="478"></a></p>

<p><strong>aws-ebpf-sdk-go</strong></p>

<p><a href="https://aws-oss.beachgeek.co.uk/38k">aws-ebpf-sdk-go</a> is a Golang based SDK for kernel eBPF operations i.e, load/attach/detach eBPF programs and create/delete/update maps. SDK relies on Unix bpf() system calls. This SDK currently supports eBPF program types (a. Traffic Classifiers b. XDP c. Kprobes/Kretprobes d. Tracepoint probes), and Ring buffer (would need kernel 5.10+). The SDK currently does not support Map in Map and Perf buffer. This is the first version of SDK and interface is subject to change so kindly review the release notes before upgrading.</p>

<p><strong>static-checker-flink</strong></p>

<p><a href="https://aws-oss.beachgeek.co.uk/38n">static-checker-flink</a> The goal of this project is to catch certain issues with Apache Flink applications fast (during build/packaging). Covered cases include Kinesis connector compatibility issues, Apache Kafka connector compatibility issues, and MSK IAM Auth library issues. As an example of how you might use this, did you know that you have to use AWS Kinesis Connector 1.15.4 or above for Apache Flink 1.15 apps? This plugin is there to stop you from building an app that has such incompatible connector versions.</p>

<p><strong>managed-service-for-apache-flink-blueprints</strong></p>

<p><a href="https://aws-oss.beachgeek.co.uk/38o">managed-service-for-apache-flink-blueprints</a> are a curated collection of Apache Flink applications. Each blueprint will walk you through how to solve a practical problem related to stream processing using Apache Flink. These blueprints can be leveraged to create more complex applications to solve your business challenges in Apache Flink, and they are designed to be extensible. We will feature examples for both the DataStream and Table API where possible.</p>

<p>Currently the repo contains two blueprints, and you will find examples of Apache Flink applications that can be run locally, on an open source Apache Flink cluster, or on Managed Service for Apache Flink cluster.</p>

<h3>
  
  
  Demos, Samples, Solutions and Workshops
</h3>

<p><strong>generative-ai-demo-on-miro</strong></p>

<p><a href="https://aws-oss.beachgeek.co.uk/38g">generative-ai-demo-on-miro</a> is the source code for a super cool demo that shows three Generative AI use-cases integrated into single solution on Miro board (digital whiteboard). It turns Python notebooks into dynamic interactive experience, where several team members can brainstorm, explore, exchange ideas empowered by privately hosted Sagemaker generative AI models. This demo can be easily extended by adding use-cases to demonstrate new concepts and solutions.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--fM1D1ox0--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_800/https://github.com/aws-samples/generative-ai-demo-on-miro/blob/main/media/genai-demo-960x540_low_fps.gif%3Fraw%3Dtrue" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--fM1D1ox0--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_800/https://github.com/aws-samples/generative-ai-demo-on-miro/blob/main/media/genai-demo-960x540_low_fps.gif%3Fraw%3Dtrue" alt="demo of generative miro board" width="" height=""></a></p>

<p><strong>lambda-rag</strong></p>

<p><a href="https://aws-oss.beachgeek.co.uk/38h">lambda-rag</a> is  a Retrieval Augmented Generation Chat AI Demo from AWS Hero Ken Collins. This OpenAI based RAG chat application that can help you learn about AI retrieval patterns. The technologies here are beginner friendly and easy to deploy to AWS Lambda. You will need an OpenAI API key to run this application, so check out the README for more details on other dependencies.</p>

<p>To help you get started and help explain everything,  Ken has put together a couple of great blog posts that really do a fantastic job of explaining the approach and the details. Make sure you read <a href="https://aws-oss.beachgeek.co.uk/38j">RAGs To Riches - Part #1 Generative AI &amp; Retrieval</a>, and the not surprisingly named, <a href="https://aws-oss.beachgeek.co.uk/38i">RAGs To Riches - Part #2 Building On Lambda</a></p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--bRnT2h2w--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://raw.githubusercontent.com/metaskills/lambda-rag/main/public/lambda-rag-hats-light.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--bRnT2h2w--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://raw.githubusercontent.com/metaskills/lambda-rag/main/public/lambda-rag-hats-light.png" alt="example demo screenshot of rag demo app" width="800" height="514"></a></p>

<p><strong>griptape-hello-world</strong></p>

<p><a href="https://aws-oss.beachgeek.co.uk/38e">griptape-hello-world</a> Griptape is an open source project that provides an enterprise grade alternative to tools like LangChain, and in this repo I share some code that I put together whilst testing it out as part of writing a short blog post on this project, <a href="https://aws-oss.beachgeek.co.uk/38f">Getting gnarly with AI - a quick look at Griptape, an enterprise ready alternative to LangChain</a>. Let me know what you think if you try this out.</p>

<p><strong>genai-jumpstart-amplify-cdk-app</strong></p>

<p><a href="https://aws-oss.beachgeek.co.uk/383">genai-jumpstart-amplify-cdk-app</a> In this project we show you how you can take a SageMaker Generative AI model, expose it as a SageMaker Endpoint and consume the Foundational Model in a React Amplify front end. This sample project also demonstrates an implementation of Retrieval Augmented Generation using AWS OpenSearch. The project illustrates how to take sample documents and use a SageMaker Endpoint running an Embeddings LLM to get the embeddings and create an embeddings index within OpenSearch. The app integrates with Cognito for authentication. All the backend components including Lambda, SageMaker Endpoints, OpenSearch, Fargate all run within a VPC. </p>

<p>Jay Pillai, Shikhar Kwatra, and Karthik Sonti have put together a detailed blog post, <a href="https://aws-oss.beachgeek.co.uk/384">Build a secure enterprise application with Generative AI and RAG using Amazon SageMaker JumpStart</a>, to help bootstrap you with this code.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--wBPu8eJg--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/23/genai-1.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--wBPu8eJg--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2023/08/23/genai-1.png" alt="overview of genai amplify demo app architecture" width="800" height="590"></a></p>

<h3>
  
  
  AWS and Community blog posts
</h3>

<p><strong>Community round up</strong></p>

<p>The community round up is my favourite part of the newsletter, as I get to read about some of the great open source work being done by the AWS community. This week starts off with AWS Community Builder Supratip Banerjee who takes a look at how to build Data version control using lakeFS, an open-source project that provides format-agnostic version control for data lakes, in the post <a href="https://aws-oss.beachgeek.co.uk/38a">A Step-by-Step Guide to Implementing Data Version Control</a>. Next up we have Nathan Peck who has put together <a href="https://aws-oss.beachgeek.co.uk/38b">Deploy Jupyter notebook container with Amazon ECS</a>, which is a nice detailed blueprint that shows how you can deploy Jupyter notebooks on Amazon ECS, leveraging underlying infrastructure optimised for AI (AWS Inferentia and AWS Trainium instance types). AWS Community Builders Lionel Tchami takes a look at setting up CI/CD pipelines using GitLab in his post, <a href="https://aws-oss.beachgeek.co.uk/38c">Every Project Deserves its CI/CD pipeline, no matter how small</a>, something I think we can all agree on. To wrap things up this week, we finish with Dr. Aparna Sundar who has put together <a href="https://aws-oss.beachgeek.co.uk/38d">OpenSearch Dashboards: A usability snapshot</a> that takes a look at the approach taken to enhance the user experience for OpenSearch users.</p>

<p><strong>Amazon Corretto</strong></p>

<p>Amazon Corretto Crypto Provider (ACCP)  is a collection of high-performance cryptographic implementations exposed via standard JCA/JCE interfaces, something I have spoken and demoed in the past. It is super cool stuff! I was therefore delighted when I saw Will Childs-Klein's post, <a href="https://aws-oss.beachgeek.co.uk/37z">Accelerating JVM cryptography with Amazon Corretto Crypto Provider 2</a> which looks at the updated version (ACCP 2) delivers comprehensive performance enhancements, with some algorithms (such as elliptic curve key generation) seeing a greater than 13-fold improvement over ACCP 1. This release also sees changes to the backing cryptography library for ACCP from OpenSSL (used in ACCP 1) to the AWS open source cryptography library, AWS libcrypto (AWS-LC). If you are a Java developer, then this is a must read post this week.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--htytlXIK--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://d2908q01vomqb2.cloudfront.net/22d200f8670dbdb3e253a90eee5098477c95c23d/2023/08/29/img1-2.jpg" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--htytlXIK--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://d2908q01vomqb2.cloudfront.net/22d200f8670dbdb3e253a90eee5098477c95c23d/2023/08/29/img1-2.jpg" alt="overview of accp2 vs accp1 benchmark" width="800" height="448"></a></p>

<p><strong>Smithy</strong></p>

<p>Smithy is an open-source Interface Definition Language (IDL) and set of tools for building web services, created by AWS. AWS uses Smithy to model services, generate server scaffolding, generate SDKs for multiple languages, and generate AWS SDKs. Andrew Foss is excited to announce the release of a new capability, which he writes about in his post <a href="https://aws-oss.beachgeek.co.uk/389">Creating Smithy Projects with Smithy Init</a>. The release of the init command in Smithy CLI, enables developers to create new Smithy projects quickly and easily. Jump into the post to find out more about Smithy and this new update. [hands on]</p>

<p><strong>Other posts and quick reads</strong></p>

<ul>
<li>
<a href="https://aws-oss.beachgeek.co.uk/380">Introducing Amazon MSK as a source for Amazon OpenSearch Ingestion</a> looks at Amazon MSK as a source to Amazon OpenSearch Ingestion, a serverless, fully managed, real-time data collector for OpenSearch Service that makes this ingestion even easier [hands on]</li>
</ul>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--3-aFYt6E--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://d2908q01vomqb2.cloudfront.net/b6692ea5df920cad691c20319a6fffd7a4a766b8/2023/08/22/BDB-3631-image001.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--3-aFYt6E--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://d2908q01vomqb2.cloudfront.net/b6692ea5df920cad691c20319a6fffd7a4a766b8/2023/08/22/BDB-3631-image001.png" alt="overview of amazon msk and opensearch ingestion" width="800" height="340"></a></p>

<ul>
<li>
<a href="https://aws-oss.beachgeek.co.uk/381">Query your Iceberg tables in data lake using Amazon Redshift (Preview)</a> provides an example of querying an Iceberg table in Redshift using files stored in Amazon S3, demonstrating some of the key features like efficient row-level update and delete, and the schema evolution experience [hands on]</li>
</ul>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--EDk-x2sa--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://d2908q01vomqb2.cloudfront.net/b6692ea5df920cad691c20319a6fffd7a4a766b8/2023/08/29/BDB-3187-image001.jpg" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--EDk-x2sa--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://d2908q01vomqb2.cloudfront.net/b6692ea5df920cad691c20319a6fffd7a4a766b8/2023/08/29/BDB-3187-image001.jpg" alt="overview of apache iceberg tables in redshift" width="800" height="827"></a></p>

<ul>
<li>
<a href="https://aws-oss.beachgeek.co.uk/386">Optimization with OpenQAOA on Amazon Braket</a> explores how the open source project OpenQAOA is integrated  with Amazon Braket, demonstrating how to cast an optimisation problem</li>
<li>
<a href="https://aws-oss.beachgeek.co.uk/387">Build streaming data pipelines with Amazon MSK Serverless and IAM authentication</a> shows you how to create a serverless integration Lambda function between API Gateway and MSK Serverless as a way to do IAM authentication when your producer is not written in Java [hands on]</li>
</ul>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--VRwlfd-B--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://d2908q01vomqb2.cloudfront.net/b6692ea5df920cad691c20319a6fffd7a4a766b8/2023/08/24/image001.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--VRwlfd-B--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://d2908q01vomqb2.cloudfront.net/b6692ea5df920cad691c20319a6fffd7a4a766b8/2023/08/24/image001.png" alt="overview of Amazon MSK serverless and IAM authentication" width="800" height="353"></a></p>

<ul>
<li>
<a href="https://aws-oss.beachgeek.co.uk/388">Use the reverse token filter to enable suffix matching queries in OpenSearch</a> gives a hands on guide on how you can implement a suffix-based search [hands on]</li>
</ul>

<h3>
  
  
  Quick updates
</h3>

<p><strong>AWS Toolkit for Visual Studio</strong></p>

<p>Announced last week was news that the AWS Toolkit for Visual Studio is now generally available on the Arm64 version of Visual Studio (aka ‚ÄúArm64 Visual Studio‚Äù). This release enables a Visual Studio user on a native Windows Arm64 device or on a device emulating Windows Arm64 on a M class Apple device to leverage the same AWS tooling that has been available to x64 versions of Visual Studio. You can read the full details in the post, <a href="https://aws-oss.beachgeek.co.uk/382">AWS Toolkit for Visual Studio adds support for Arm64 Visual Studio</a></p>

<p><strong>AWS SDK</strong></p>

<p>There is an upcoming change in the S3 GetObjectAttributes API, and so John Viegas has put together a post that users of the AWS SDK for Java v2, AWS SDK for .NET v3, and AWS Tools for PowerShell should read and understand how they can prepare. You can catch the post here, <a href="https://aws-oss.beachgeek.co.uk/385">Update to AWS SDK for Java v2, AWS SDK for .NET v3, and AWS Tools for PowerShell when using S3 GetObjectAttributes API</a></p>

<p><strong>Apache Airflow</strong></p>

<p>Amazon Managed Workflows for Apache Airflow (MWAA) has added certifications for International Organization for Standardization (ISO) and Information Security Registered Assessors Program (IRAP). Amazon Web Services (AWS) maintains certifications through extensive audits of its controls to ensure that information security risks that affect the confidentiality, integrity, and availability of company and customer information are appropriately managed. </p>

<p>Amazon MWAA is a managed orchestration service for Apache Airflow that makes it easier to set up and operate end-to-end data pipelines in the cloud. Amazon MWAA has certification for compliance with ISO/IEC 27001:2013, 27017:2015, 27018:2019, 27701:2019, 22301:2019, 9001:2015, and CSA STAR CCM v4.0. You can download copies of the AWS ISO certificates and use them to jump-start your own certification efforts. Further, with IRAP certification, you can meet the Australian Government Information Security Manual (ISM) control objectives while using Amazon MWAA.</p>

<p>In addition to ISO and IRAP certification, Amazon MWAA is also Health Insurance Portability and Accountability Act (HIPAA) eligible, in scope for System and Organization Controls (SOC) reports, and Payment Card Industry Data Security Standard (PCI) compliant. </p>

<p><strong>MySQL and PostgreSQL</strong></p>

<p>Amazon Relational Database Service (RDS) announces Amazon RDS Extended Support for Amazon Aurora and Amazon RDS database instances running MySQL 5.7, PostgreSQL 11, and higher major versions beyond the community end of life. Amazon RDS Extended Support provides you more time, up to three years, to upgrade to a new major version to help you meet your business requirements. Extended Support is available for Aurora MySQL-compatible edition, Aurora PostgreSQL-compatible edition, RDS for MySQL and RDS for PostgreSQL.</p>

<p>Starting in December, 2023, you will be able to opt-in to Amazon RDS Extended Support through the AWS Console, CLI, and APIs. When you opt-in to Extended Support, Amazon RDS will provide critical security and bug fixes for your MySQL and PostgreSQL databases after the community ends support for a major version. You can run your databases on Amazon Aurora and Amazon RDS with Extended Support for up to three years beyond a major version‚Äôs end of standard support date. Learn more about Extended Support, including supported engine versions, in the Amazon Aurora user guide and Amazon RDS User Guide.</p>

<p>Amazon RDS Extended Support is now available for Aurora MySQL-Compatible version 2 and higher, Aurora PostgreSQL-Compatible version 11 and higher, RDS for MySQL major versions 5.7 and higher, and RDS for PostgreSQL major versions 11 and higher in AWS Commercial and AWS GovCloud (US) Regions.</p>

<p>Find out more by reading the post, <a href="https://aws-oss.beachgeek.co.uk/37w">Introducing Amazon RDS Extended Support for MySQL databases on Amazon Aurora and Amazon RDS</a>, where Vijay Karumajji makes some compelling arguments why you should try and upgrade, but failing that, how  Amazon RDS Extended Support can help.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--8n2jr4FJ--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://d2908q01vomqb2.cloudfront.net/887309d048beef83ad3eabf2a79a64a389ab1c9f/2023/09/01/DBBLOG-3499_img1-1024x308.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--8n2jr4FJ--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://d2908q01vomqb2.cloudfront.net/887309d048beef83ad3eabf2a79a64a389ab1c9f/2023/09/01/DBBLOG-3499_img1-1024x308.png" alt="overview of extended support diagram for MySQL" width="800" height="241"></a></p>

<p><strong>PostreSQL</strong></p>

<p>Aside from the Extended support news just mentioned, there are a couple of other updates worth noting.</p>

<p>First is news that Amazon Relational Database Service (RDS) for PostgreSQL now supports the h3-pg extension, which provides an API to H3, an open-source hexagonal, hierarchical geospatial indexing system. With this extension, you can perform different kinds of spatial analysis over large datasets, including efficient indexing and lookups, modeling flow through a grid, and applying machine learning models over your geospatial data stored in Amazon RDS for PostgreSQL. The H3 library provides an invariant set of hexagonal map tiles over multiple layers of resolution. This allows the h3-pg extension to index your geospatial data so you can efficiently query data on your maps. For example, a retailer planning new outlets may want to create a heatmap visualisation using traffic, mobility, demographic, and other geospatial datasets to identify locations best suited for their customers. You can also use H3 and PostGIS together to perform different geospatial analyses. h3-pg is available on database instances in Amazon RDS running PostgreSQL 15.4, 14.9, 13.12 and higher in all applicable AWS Regions.</p>

<p>Finally, Amazon RDS for PostgreSQL 16 Release Candidate 1 (RC1) is now available in the Amazon RDS Database Preview Environment, allowing you to evaluate the pre-release of PostgreSQL 16 on Amazon RDS for PostgreSQL. You can deploy PostgreSQL 16 RC1 in the Preview Environment and have the same benefits of a fully managed database, making it simpler to set up, operate, and monitor databases. PostgreSQL 16RC1 in the Preview Environment also includes support for logical decoding on read replicas, AWS libcrypto (AWS-LC), and over 80 PostgreSQL extensions such as pgvector, pg_tle, h3-pg, pg_cron, and rdkit.</p>

<p>The PostgreSQL community released PostgreSQL 16 RC1 on August 31, 2023 that enables logical replication from standbys and includes numerous performance improvements. PostgreSQL 16 also adds support for SQL/JSON constructors and identity functions, more query types that can use parallelism, introduction of using SIMD CPU acceleration, and the ‚Äòpg_stat_io‚Äô view that provides statistics on I/O usage. The Amazon RDS Database Preview Environment supports the latest generation of instance classes that are retained for a maximum period of 60 days and are automatically deleted after the retention period. Amazon RDS database snapshots that are created in the Preview Environment can only be used to create or restore database instances within the Preview Environment. You can use the PostgreSQL dump and load functionality to import or export your databases from the Preview Environment.</p>

<p><strong>AWS Serverless Application Model (SAM)</strong></p>

<p>The AWS Serverless Application Model (SAM) Command Line Interface (CLI) announces the launch of SAM CLI local testing and debugging on HashiCorp Terraform. The AWS SAM CLI is a developer tool that makes it easier to build, test, package, and deploy serverless applications. Terraform is an infrastructure as code tool that lets you build, change, and version cloud and on-premises resources safely and efficiently.</p>

<p>Customers can now use the SAM CLI to locally test and debug AWS Lambda functions and Amazon API Gateway defined in their Terraform application. SAM CLI can read the infrastructure resource information from the Terraform project and start Lambda functions and API Gateway endpoints locally running in a Docker container. Customers can invoke their function or API endpoint with an event payload, or attach a debugger using AWS toolkits on IDE to step through the Lambda function code. Previously, SAM CLI only supported local testing and debugging on CloudFormation templates. With this change, Terraform users can use the SAM CLI local testing commands like sam local start-api, sam local start-lambda and sam local invoke on their Terraform projects to speed up their development cycles. They can also use sam local generate command to generate mock test events for local testing.</p>

<p>This feature is supported with Terraform version 1.1+ and you can find out more by reading the post from Eric Johnson, <a href="https://aws-oss.beachgeek.co.uk/37v">AWS SAM support for HashiCorp Terraform now generally available</a></p>

<p><strong>PyTorch</strong></p>

<p>SageMaker Multi-Model Endpoint (MME) is a fully managed capability that allows customers to deploy 1000s of models on a single SageMaker endpoint and reduce costs. Until today, MME was not supported for PyTorch models deployed using TorchServe. Now, customers can use MME to deploy 1000s of PyTorch models using TorchServe to reduce inference costs.</p>

<p>Customers are increasingly building ML models using PyTorch to achieve business outcomes, To deploy these ML models, customers use TorchServe on CPU/GPU instances to meet desired latency and throughput goals. However, costs can add up if customers are deploying 10+ models. With MME support for TorchServe, customers can deploy 1000s of PyTorch based models on a single SageMaker endpoint. Behind the scenes, MME will run multiple models on a single instance and dynamically load/unload models across multiple instances based on the incoming traffic. With this feature, customers can save costs, as they can share instances behind an endpoint across 1000s of models and only pay for the number of instances used. </p>

<p>This feature supports PyTorch models which use SageMaker TorchServe Inference Container with all machine learning optimised CPU instances and single GPU instances in ml.g4dn, ml.g5, ml.p2, ml.p3 family. It is also available in all regions supported by Amazon SageMaker. </p>

<p><strong>lightsail-miab-installer</strong></p>

<p>This is a project from my fellow developer advocate Rio Astamal, that provides a user-friendly command-line tool to streamline the setup of Mail-in-a-Box on Amazon Lightsail. Rio contacted me that <a href="https://aws-oss.beachgeek.co.uk/2ym">lightsail-miab-installer</a> has had an update so go check out the changelog for updates. </p>

<h3>
  
  
  Videos of the week
</h3>

<p><strong>Start building with PL/Rust in Amazon RDS for PostgreSQL</strong></p>

<p>Rust combines the performance and resource efficiency of compiled languages like C with mechanisms that limit the risks from unsafe memory use. As a PostgreSQL trusted procedural language, PL/Rust provides memory safety so that an unprivileged user can run code in the database without the risk of crashing the database due to a software defect that corrupts memory. Developers can also package PL/Rust code as Trusted Language Extensions (TLE) for PostgreSQL to run on Amazon RDS. RDS for PostgreSQL customers can now use Rust to build high performance user defined functions to extend PostgreSQL for compute-intensive data processing. </p>

<p>In this session, Sukhpreet Bedi provides a brief introduction to Rust, walk you through how to deploy RDS for PostgreSQL with PL/Rust enabled, and show you how to write high-performance Rust code directly to your database.</p>

<p><iframe width="710" height="399" src="https://www.youtube.com/embed/ZluZH0Q5Mhw">
</iframe>
</p>

<p><strong>Mastering GitOps with Flux: Step-by-Step Guide for Effective Implementation</strong></p>

<p>GitOps is an effective way to achieve continuous deployment for Kubernetes clusters while meeting enterprise requirements like security, separation of privileges, audibility, and agility. In this series of 4 demos, Betty Zheng will show you some good practices for GitOps based on EKS and Flux CD. Check the YouTube listing for the supporting code so you can follow along too.</p>

<p><iframe width="710" height="399" src="https://www.youtube.com/embed/_jdq7BhK4IQ">
</iframe>
</p>

<p><strong>Open Source Brief</strong></p>

<p>Now featured every week in the AWS Community Radio show, grab a quick five minute recap of the weekly open source newsletter from yours truely.</p>

<p><iframe width="710" height="399" src="https://www.youtube.com/embed/zQjtBsjjCcc">
</iframe>
</p>

<p>Check out the <a href="https://aws-oss.beachgeek.co.uk/359">playlist here</a>.</p>

<p><strong>Build on Open Source</strong></p>

<p>For those unfamiliar with this show, Build on Open Source is where we go over this newsletter and then invite special guests to dive deep into their open source project. Expect plenty of code, demos and hopefully laughs. We have put together a playlist so that you can easily access all (sixteen) of the episodes of the Build on Open Source show. <a href="https://aws-oss.beachgeek.co.uk/episodes">Build on Open Source playlist</a>.</p>

<p>We are currently planning the third series - if you have an open source project you want to talk about, get in touch and we might be able to feature your project in future episodes of Build on Open Source.</p>

<h1>
  
  
  Events for your diary
</h1>

<p>If you are planning any events in 2023, either virtual, in person, or hybrid, get in touch as I would love to share details of your event with readers. </p>

<p><strong>Building ML capabilities with PostgreSQL and pgvector extension</strong><br>
<strong>YouTube, 14th September 4pm UK time</strong></p>

<p>Generative AI and Large Language Models (LLMs) are powerful technologies for building applications with richer and more personalized user experiences. Application developers who use Amazon Aurora for PostgreSQL or Amazon RDS for PostgreSQL can use pgvector, an open-source extension for PostgreSQL, to harness the power of generative AI and LLMs for driving richer user experiences. Register now to learn more about this powerful technology.</p>

<p>Watch it <a href="https://aws-oss.beachgeek.co.uk/325">live on YouTube</a>.</p>

<p><strong>Build ML into your apps with PostgreSQL and the pgvector extension</strong><br>
<strong>YouTube, 21st September 4pm UK time</strong></p>

<p>This office hours session is a follow up for those who attended the fireside chat titled "Building ML capabilities into your apps with PostgreSQL and the open-source pgvector extension". Others are also welcome. Office hours attendees can ask questions related to this topic. Application developers who use Amazon Aurora for PostgreSQL or Amazon RDS for PostgreSQL can use pgvector, an open-source extension for PostgreSQL, to harness the power of generative AI and LLMs for driving richer user experiences. Join us to ask your questions and hear the answers to the most frequently asked questions about the pgvector extension for PostgreSQL.</p>

<p>Watch it <a href="https://aws-oss.beachgeek.co.uk/326">live on YouTube</a>.</p>

<p><strong>Open Source Summit, Europe</strong><br>
<strong>September 19th-21st, Bilboa Spain</strong></p>

<p>"Open Source Summit is the premier event for open source developers, technologists, and community leaders to collaborate, share information, solve problems, and gain knowledge, furthering open source innovation and ensuring a sustainable open source ecosystem. It is the gathering place for open-source code and community contributors." You will find AWS as well as myself at Open Source Summit this year, so come by the AWS booth and say hello - from the glimpses I have seen so far, it is going to be awesome! Find out more at the official site, <a href="https://aws-oss.beachgeek.co.uk/31f">Open Source Summit Europe 2023</a>.</p>

<p><strong>OpenSearchCon</strong><br>
<strong>Seattle, September 27-29, 2023</strong></p>

<p>Registration is now open source OpenSearchCon. Check out this post from Daryll Swager, <a href="https://aws-oss.beachgeek.co.uk/2zk">Registration for OpenSearchCon 2023 is now open!</a> that provides you with what you can expect, and resources you need to help plan your trip.</p>

<p><strong>CDK Day, 2023</strong><br>
<strong>Online, 29th September 2023</strong></p>

<p>Back for the fourth instalment, this Community led event is a must attend for anyone working with infrastructure as code using the AWS Cloud Development Kit (CDK). It is intended to provide learning opportunities for all users of the CDK and related libraries. The event will be live streamed on YouTube, and you check more at the website, <a href="https://aws-oss.beachgeek.co.uk/fr">CDK Day</a> </p>

<p><strong>All Things Open</strong><br>
<strong>October, 15th-17th, Raleigh Convention Center, Raleigh, North Carolina</strong></p>

<p>I will be attending and speaking at All Things Open, looking at Apache Airflow as an container orchestrator. I will be there with a bunch of fellow AWS colleagues, and I hope to meet some of you there. Check us out at the AWS booth, where you will find me and the other AWS folk throughout the event. Check out the event and sessions/speakers at the official webpage for the event, <a href="https://aws-oss.beachgeek.co.uk/31e">AllThingsOpen 2023</a></p>

<p><strong>Open Source India</strong><br>
<strong>October 19th-21st, NIMHANS Convention Center, Bengaluru</strong></p>

<p>One of the most important open source events in the region, Open Source India will be welcoming thousands of attendees all to discuss and learn about open source technologies. I will be there too, doing a talk so I would love to meet with any of you who are also planning on attending. Check out more details on their web page, <a href="https://aws-oss.beachgeek.co.uk/31d">here</a>.</p>

<p><strong>Cortex</strong><br>
<strong>Every other Thursday, next one 16th February</strong></p>

<p>The Cortex community call happens every two weeks on Thursday, alternating at 1200 UTC and 1700 UTC. You can check out the GitHub project for more details, go to the <a href="https://aws-oss.beachgeek.co.uk/2h5">Community Meetings</a> section. The community calls keep a rolling doc of previous meetings, so you can catch up on the previous discussions. Check the <a href="https://aws-oss.beachgeek.co.uk/2h6">Cortex Community Meetings Notes</a> for more info.</p>

<p><strong>OpenSearch</strong><br>
<strong>Every other Tuesday, 3pm GMT</strong></p>

<p>This regular meet-up is for anyone interested in OpenSearch &amp; Open Distro. All skill levels are welcome and they cover and welcome talks on topics including: search, logging, log analytics, and data visualisation.</p>

<p>Sign up to the next session, <a href="https://aws-oss.beachgeek.co.uk/1az">OpenSearch Community Meeting</a></p>

<h3>
  
  
  Stay in touch with open source at AWS
</h3>

<p>Remember to check out the <a href="https://aws.amazon.com/opensource/?opensource-all.sort-by=item.additionalFields.startDate&amp;opensource-all.sort-order=asc">Open Source homepage</a> to keep up to date with all our activity in open source by following us on <a href="https://twitter.com/AWSOpen">@AWSOpen</a></p>

 </details> 
 <hr /> 

 #### - [üñä I am building a pastebin alternative!](https://dev.to/shaancodes/i-am-building-a-pastebin-alternative-57o2) 
 <details><summary>Article</summary> <p>Hi.<br>
I wanted to learn T3 stack as it is trend right now. So what better way is there to learn a particular stack than actually creating a project in it. But, I did not wanted to create the traditional recipe app, social media app or a boring e-commerce app. I wanted to create something which can be used by others also.</p>

<p>So, I thought to myself what are the apps which I use, but it could've been better if I built it. I thought of lot of apps, but later came across pastebin. I thought to myself, "I could build it better".</p>

<h2>
  
  
  Is it a regular pastebin clone?
</h2>

<p>No, it's not exactly a pastebin clone, but rather I'm planning it to build it as an alternative to it. It's going to be better, with beautiful UI and everything. </p>

<h2>
  
  
  How is it going to be different?
</h2>

<p>The difference is I am gonna let users write notion like documents and then share it, unlike pastebin which only lets us share text. For writing documents, I'm gonna use <a href="https://novel.sh/">Novel.sh</a>. It is a WYSIWYG editor which provides interface and features similar to Notion. It also lets us use OpenAI API to integrate AI into it.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--pEW7PWB8--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/2v4xi3tkwerp9a7e23yd.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--pEW7PWB8--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/2v4xi3tkwerp9a7e23yd.png" alt="Novel.sh" width="800" height="693"></a></p>

<p>It will have all the regular features like document sharing, password protection, document exposure, document expiration etc. For now, I'm planning to build a MVP in a week or so, and later I'll improve it by introducing more features into it.</p>

<h2>
  
  
  What tech stack I'm planning to use?
</h2>

<ul>
<li>T3 stack</li>
<li>Novel.sh (WYSIWYG editor)</li>
<li>shadcn/ui</li>
<li>MySql</li>
<li>PlanetScale</li>
<li>Vercel</li>
</ul>

<p>I am bad at naming things üòÅ, I had hard time thinking about a name for this project. I came up with "docshare", but I think it can be further improved. I'd appreciate it if you guys can help me come up with a perfect name for this project. Thanks in advance!</p>

<h3>
  
  
  My Socials
</h3>

<p>Twitter - <a href="https://twitter.com/shaancodes">https://twitter.com/shaancodes</a></p>

<p>Instagram - <a href="https://www.instagram.com/shaancodes/">https://www.instagram.com/shaancodes/</a></p>

<p>GitHub - <a href="https://github.com/shaan-alam/">https://github.com/shaan-alam/</a></p>

 </details> 
 <hr /> 
<!-- BLOG-POST-LIST:END -->
</table>
</details>


<!-- TODO
Change the 3stats boxes around, possibly two on top and one on bottom
Fix RSSfeed
Fix Spotify Playlists
Fix Socials [Portfolio, Discord, Linkedin]
In the future, add Public Repositories of Selected Projects
-->
