<!-- VISITOR BADGE -->
<!-- https://github.com/hehuapei/visitor-badge -->

<img align="right" src="https://visitor-badge.laobi.icu/badge?page_id=mao1910.mao1910&left_color=%2379DAF9&right_color=%23FE6E96" />


<!-- TYPING SVG -->
<!-- https://github.com/DenverCoder1/readme-typing-svg -->

<h1 align="center">
    <img src="https://readme-typing-svg.herokuapp.com/?font=Righteous&size=35&center=true&vCenter=true&width=500&height=70&color=FE6E96&font=poppins&duration=5000&lines=Hi+There!+👋;+I'm+Mao!;" />
</h1>

<br/>

<!-- CODE/TERMINAL ABOUT ME -->
<h1 align="center">
<img src="./assets/terminal-5.gif" alt="Terminal" />
</h1>

<br/><br/><br/>


<!-- TECHNOLOGIES LOGOS -->
<!-- https://github.com/tandpfun/skill-icons -->

<h2 align="center">💻 Languages / Frameworks / Tools ⚒️</h2>
<div align="center">
    <img src="https://skillicons.dev/icons?i=javascript,typescript,angular,react,html,css,scss,bootstrap,cs,java,spring" />
    <img src="https://skillicons.dev/icons?i=flutter,firebase,supabase,mysql,git,github,gitlab,vscode,idea,maven,figma" />
</div>

<br/><br/><br/>


<!-- CONTRIBUTIONS SNAKE GAME -->
<!-- https://github.com/Platane/snk -->

<div align="center">
  <h2> My Contributionssss🐍 </h2>
  <br>
  <img alt="contributions-eating Snake" src="https://raw.githubusercontent.com/mao1910/mao1910/output/github-contribution-grid-snake.svg" />

  <!-- Four lines below suggested by Planate for Dark mode-->
  <picture>
  <source media="(prefers-color-scheme: dark)" srcset="github-snake-dark.svg" />
  <source media="(prefers-color-scheme: light)" srcset="github-snake.svg" />
  </picture>
  
  <br/><br/><br/>
</div>


<!-- GITHUB STATS -->
<!-- https://github.com/DenverCoder1/github-readme-streak-stats -->
<!-- https://github.com/anuraghazra/github-readme-stats -->
<!-- https://github-readme-stats-mao1910.vercel.app/ My own Vercel deployment-->

<h2 align="center"> Stats📝 </h2>
  <br>
<div align=center>
  <img width=429 src="https://github-readme-stats-mao1910.vercel.app/api?username=mao1910&count_private=true&show_icons=true&theme=dracula&rank_icon=github&hide=contribs&border_radius=10&border_color=79DAF9" alt="github stats"/>
  <img width=396 src="https://streak-stats.demolab.com/?user=mao1910&count_private=true&theme=dracula&currStreakNum=79DAF9&currStreakLabel=FE6E96&border_radius=10&border=79DAF9" alt="streak stats"/>
  <br/>
  <img src="https://github-readme-stats-mao1910.vercel.app/api/top-langs/?username=mao1910&layout=compact&theme=dracula&border_radius=10&size_weight=0.5&count_weight=0.5&border_color=79DAF9" alt="languages stats" />
</div>

<br/><br/><br/>


<!-- FOOTER -->
<!-- https://github.com/DenverCoder1/readme-typing-svg -->
<!-- https://readme-typing-svg.demolab.com/demo/ -->

<a href="https://git.io/typing-svg"><img src="https://readme-typing-svg.demolab.com?font=Poppins&pause=1000&color=FE6E96&width=535&lines=Thanks+for+dropping+by!;Feel+free+to+check+any+of+the+Socials+below+%F0%9F%91%87;Or+the+Joke+Of+The+Day+if+you're+down+for+a+giggle+%F0%9F%98%9D;Hope+to+see+you+again+%F0%9F%91%8A;Uh%3F+You're+still+here%3F;Well...+I'm+running+out+of+things+to+say...;Tell+you+what%2C+due+to+your+effort+and+perseverance%2C;I+shall+present+you+with+a+short+poem%3A;%22To+code%2C+or+not+to+code%2C+that+is+the+question%3A;Whether+'tis+nobler+in+the+IDE+to+debug;The+errors+and+issues+of+outrageous+software%2C;Or+to+take+up+the+keyboard+against+a+sea+of+bugs;And+by+coding%2C+end+them.%22;by+William+Shakespeare%2C+probably.+;Pretty+sure+that's+Hamlet's.;Alrighty%2C+this+has+been+fun.;But+I'll+restart+the+loop+now...+see+ya+soon!" alt="Typing SVG" /></a>


<!--  SOCIAL NETWORKS -->
<!-- https://github.com/alexandresanlim/Badges4-README.md-Profile -->

  <div> 
    <a href="https://www.deviantart.com/madeinkobaia/art/my-profile-is-under-construction-265626465" target="_blank"><img src="https://img.shields.io/badge/-LinkedIn-%230077B5?style=for-the-badge&logo=linkedin&logoColor=white" target="_blank"></a> <!-- ADD LINKEDIN PROFILE -->
    <a href = "https://www.nicepng.com/ourpic/u2q8o0t4t4r5o0r5_website-under-construction-png-graphic-transparent-website-under/"><img src="https://img.shields.io/badge/Portfolio-4285F4?style=for-the-badge&logo=Google-chrome&logoColor=white" target="_blank"></a> <!-- ADD PORTFOLIO WEBSITE -->
    <a href="https://discord.gg" target="_blank"><img src="https://img.shields.io/badge/Discord-7289DA?style=for-the-badge&logo=discord&logoColor=white" target="_blank"></a> <!-- ADD DISCORD -->
    <a href = "mailto:mao1910dev@gmail.com"><img src="https://img.shields.io/badge/Gmail-D14836?style=for-the-badge&logo=gmail&logoColor=white" target="_blank"></a>
  </div>


<!-- SPOTIFY PLAYING-->
<!-- https://github.com/novatorem/novatorem -->
<!-- https://spotify-now-playing-novatorem-git-main-mao1910.vercel.app/ My own Vercel deployment-->

[<img width=438px src="https://spotify-now-playing-git-main-mao1910.vercel.app//api/spotify/?border_color=FE6E96" alt="Mao Spotify Now Playing" />](https://open.spotify.com/user/31542et242zglhf42ydrtqgvuvde)


<!-- JOKE OF THE DAY -->
<!-- https://github.com/ABSphreak/readme-jokes -->
<!-- https://readme-jokes-git-master-mao1910.vercel.app/ My own Vercel deployment-->

<details>
<summary>I've got a Joke for you. Wanna hear it? 🙈</summary>

<br/>

 <tr>
 <td style="padding-top:4px"><img src = "https://readme-jokes-git-master-mao1910.vercel.app/api?&theme=dracula"></td>
 </tr>

</details>


<!-- RSS FEED -->
<!-- https://github.com/gautamkrishnar/blog-post-workflow -->

<details>
<summary>📕 &nbsp;RSS feed</summary>

<br/>

<!-- BLOG-POST-LIST:START -->
 #### - [Oracle-Linux 8'de Chronyd ile NTP İstemcisi Yapılandırma](https://dev.to/aciklab/oracle-linux-8de-chronyd-ile-ntp-istemcisi-yapilandirma-1p6f) 
 <details><summary>Article</summary> <ul>
<li>Chronyd Servisinin Yüklenmesi ve Etkinleştirilmesi:</li>
</ul>

<p>Öncelikle, chronyd servisinin yüklü olup olmadığını kontrol edin. Eğer yüklü değilse, yükleyin:<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>sudo dnf install chrony
</code></pre>

</div>



<p>Servisi etkinleştirin ve başlatın:<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>sudo systemctl enable --now chronyd
</code></pre>

</div>



<ul>
<li>Chrony Konfigürasyon Dosyasının Düzenlenmesi:</li>
</ul>

<p>Özel bir NTP sunucusu kullanmak için, chrony konfigürasyon dosyasını düzenleyin:<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>sudo nano /etc/chrony/chrony.conf
</code></pre>

</div>



<p>Dosyada, aşağıdaki gibi bir veya birden fazla server veya pool satırı ekleyin (örneğin "ntp.ulakbim.gov.tr"):<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>server ntp.ulakbim.gov.tr iburst
</code></pre>

</div>



<p>İsterseniz IP adresi de kullanabilirsiniz. iburst opsiyonu, zaman senkronizasyonunu hızlandırmak için kullanılır.</p>

<ul>
<li>Chronyd Servisini Yeniden Başlatma:</li>
</ul>

<p>Konfigürasyon dosyasını düzenledikten sonra, servisi yeniden başlatın:<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>sudo systemctl restart chronyd
</code></pre>

</div>



<ul>
<li>Senkronizasyon Durumunu Kontrol Etme:</li>
</ul>

<p>chronyc komutunu kullanarak senkronizasyon durumunu kontrol edebilirsiniz:<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>chronyc tracking
</code></pre>

</div>



<p>Bu komut, senkronizasyon durumu hakkında detaylı bilgi verecektir.</p>

<ul>
<li>Güvenlik Duvarı Ayarları:</li>
</ul>

<p>Eğer güvenlik duvarı etkinse, NTP trafiğine izin vermeniz gerekebilir:<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>sudo firewall-cmd --add-service=ntp --permanent
sudo firewall-cmd --reload
</code></pre>

</div>



<ul>
<li>Senronizasyon Durumunu Doğrulama:</li>
</ul>

<p>timedatctl komutunu kullanarak NTP servisinin aktif olup olmadığı kontrol edebilirsiniz:<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>timedatectl
</code></pre>

</div>



<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--QDkIHpue--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/uvolwg7s0ck66vsec5ow.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--QDkIHpue--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/uvolwg7s0ck66vsec5ow.png" alt="Image description" width="372" height="37"></a></p>

 </details> 
 <hr /> 

 #### - [How to get started with MongoDB as a Student](https://dev.to/1grace/how-to-get-started-with-mongodb-as-a-student-55j8) 
 <details><summary>Article</summary> <p>As student with a passion for the developer community, I have participated in varous hackathons, and gotten involved in my student community. </p>

<p>Throughout these experiences, I have had the opportunity to learn and develop projects using the MERN stack (MERN stands for MongoDB, Express, React, Node, after the four key technologies that make up the stack. MongoDB — document database. Express(.js) — Node.js web framework. React(.js) — a client-side JavaScript framework.) More information can be seen on their blog <a href="https://www.mongodb.com/mern-stack#:~:text=MERN%20stands%20for%20MongoDB%2C%20Express,a%20client%2Dside%20JavaScript%20framework">here.</a></p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--_fP0Hjsr--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/nzz4ooe0i3scj8s4xa63.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--_fP0Hjsr--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/nzz4ooe0i3scj8s4xa63.png" alt="Image description" width="800" height="401"></a></p>

<p>As a software engineering intern, I have had the opportunity to also see how often MongoDB is used within projects, and how its capabilities have contributed to more efficient and reliable projects. </p>

<p>Finally, In my previous semester, I had the opportunity to take a course on unstructured data, (for any students at western, CS4417 is the course!) where I was able to learn more about unstructured data, noSQL, and work on an assignment involving MongoDB, Aggregation, and MapReduce. Im happy to make seperate blog posts about these projects as well for any students interested in exploring applications and ways to use MongoDB in their own projects. </p>

<p>Overall, MongoDB is a great tool to be able to leverage in your projects! Now you might be wondering, how do I get started? </p>

<p>MLH (Major League Hacking) is a large hackathon organizer and a community that I have been involved in since the summer of 2020. </p>

<p>As mentioned in their <a href="https://news.mlh.io/major-league-hacking-mongodb-partner-to-inspire-the-next-generation-of-builders-03-27-2023">website post</a>, </p>

<blockquote>
<p>MongoDB Atlas – Best Database Platform for Your Next Hackathon<br>
MongoDB Atlas is a multi-cloud database with an integrated set of related services that allow development teams to address the growing requirements for today’s wide variety of modern applications, all in a unified and consistent user experience.</p>
</blockquote>

<p>MongoDB Atlas is more than a general-purpose database, it’s a full developer data platform – easily deploy and manage databases on-demand when and where you need them. </p>

<p>Below are some ways you could use MongoDB Atlas in your next hackathon project.</p>

<p>1) Simplify the way you integrate database functionality into your hackathon project by starting a free cluster or using your introductory $50 Atlas credits for students. </p>

<p>2) Take your hackathon project to the next level, and deploy a database to the cloud in minutes. Signing up is easy and hassle-free with no credit card required! </p>

<p>Key Benefits for Students<br>
MongoDB is one of the most prevalent database providers in the world, and we’ve got a range of opportunities to help you get started building on their platform. </p>

<p>1) Receive $50 of free MongoDB Atlas credits through the GitHub Student Developer Pack, along with a MongoDB certification ($150 in value). The Forever Free Tier is available if you are no longer a student. </p>

<p>2) Enter the “Best Use of MongoDB Atlas” challenge at an upcoming MLH event for a chance to win a M5GO iOT Starter Kit. To participate in the challenge, check out our website and register for an upcoming event! </p>

<p>Interested in taking advantage of your MongoDB Atlas perks? Check out their website here. </p>

<p>MongoDB also has developed "MongoDB University" a series of courses and ressources to support the learning and application of those learnings! I have taken some of the modules and can confirm the videos and tutorials go in depth and with the interactive nature of their tutorials, you will be engaged with the content. </p>

<p>Finally, MongoDB has <a href="https://www.mongodb.com/community/forums/c/user-groups/11">User Groups </a><br>
which bring people together to learn from and connect over their shared interest in MongoDB technologies. These are communities of developers with various skill levels and an interest in learning new technologies and applications including MongoDB and beyond, and are a great opportunity to get involved! Whether you are a beginner or a skilled individiaul, this is a safe space for users and novices to come together, learn from each other, and share what theyre doing with mongodb and other tech. </p>

<p>I recently became involved as a co-organizer for the <a href="https://www.meetup.com/toronto-mongodb-usergroup/">Toronto User Group</a> and confirm the community is welcoming for people with diverse experiences and has enabled me to meet and learn from people around the company and community. </p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--s5L7O_YG--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/fxh7b8ye337xc6exh4at.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--s5L7O_YG--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/fxh7b8ye337xc6exh4at.png" alt="Image description" width="800" height="450"></a></p>

<p>These are just starting points - there are many options for ways to get involved with MongoDB beyond this!  </p>

<p>You could build an application or library you've built using MongoDB, contribute to open source related to MongoDB, <br>
talk at a local MongoDB event, create a video or tutorial sharing what you've learned or created about MongoDB, <br>
get involved and provide support through Stack Overflow, the MongoDB Community Forum or elsewhere, and more! </p>

<p>If you had any questions feel free to leave them in the comments! </p>

 </details> 
 <hr /> 

 #### - [Fiz um push sem checar as alterações do repositório, e agora?](https://dev.to/nikolai1312/fiz-um-push-sem-checar-as-alteracoes-do-repositorio-e-agora-f7k) 
 <details><summary>Article</summary> <h4>
  
  
  *<em>Este artigo foi escrito em conjunto com <a class="mentioned-user" href="https://dev.to/donadonf">@donadonf</a> *</em>
</h4>

<p>Dentro de uma equipe de desenvolvimento nos deparamos com algumas demandas que são desenvolvidas por pares, alguns casos utilizam até a mesma branch para desenvolver a tarefa e fazem com que os desenvolvedores trabalhem 2 habilidades muito importantes: A comunicação e o versionamento de código. Neste artigo iremos tratar de uma situação que pode ser comum, podemos chamá-la de “Fiz um push e não sabia que a branch havia mudado, e agora?”. </p>

<p>Ao tentar fazer um push, provavelmente recebeu de volta uma mensagem indicando um conflito de branches, sendo a branch local em que está trabalhando e a branch remota, para onde irá o commit feito.<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>[rejected] master -&gt; master (fetch first)
error: failed to push
</code></pre>

</div>



<p>Bom, teremos um longo caminho pela frente, mas fique tranquilo porque há uma solução! </p>

<p>Primeiramente, devemos verificar os commits que já estão na branch remota e qual o nosso status em relação a ela, para isso podemos executar o comando:<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>git status
</code></pre>

</div>



<p>Receberá uma informação sobre o status das branch em que está trabalhando, dessa forma:<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>On branch nome-da-branch
Your branch and 'origin/nome-da-branch' have diverged,
and have 1 and 1 different commits each, respectively.
</code></pre>

</div>



<p>Isso indica que sua branch local está com um commit a ser enviado, mas está com um commit atrasado em relação a branch remota, nesse cenário é necessário puxar os dados da branch remota antes de realizar o push para que não tenha um conflito de versões de código. </p>

<p>Começaremos a solução do conflito entre as branches checando os logs dos commits feitos com o comando:<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>git log
</code></pre>

</div>



<p>Vamos pegar o ID do último commit feito, porque aqui estaremos visualizando um histórico dos commits feitos. Com esse ID iremos executar um hard reset na branch atual e retirar o commit do HEAD com outro comando, então a sequência de comandos será a seguinte:<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>git reset --hard ID-do-commit

git reset HEAD~1
</code></pre>

</div>



<p>Novamente, vamos checar o status das versões que estamos trabalhando com comando <code>git status</code>, veremos que alguns arquivos estão marcados como <code>Changes not staged for commit</code>, isso significa que o commit foi resetado corretamente e as alterações feitas não foram perdidas. Devemos então armazenar essas mudanças dentro do stash para que possamos fazer o commit mais tarde com o comando:<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>git stash
</code></pre>

</div>



<p>Caso a operação ocorra bem, a mensagem será a seguinte:<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>Saved working directory and index state WIP on nome-da-branch: ID-do-commit-atual-da-branch 
</code></pre>

</div>



<p>Devemos então executar o comando que irá mostrar a quantidade de arquivos que estão salvos no último stash feito.<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>git stash show
</code></pre>

</div>



<p>Como os arquivos estarão salvos no stash e branch terá voltado ao mesmo estágio da branch remota, podemos dar sequência ao procedimento padrão de um commit. Iremos checar o status da branch remota com o <code>git status</code> e depois executar um <code>git pull</code> para receber as alterações feitas na branch remota.</p>

<p>Por fim, podemos retirar os arquivos do stash porque iremos utilizá-los agora:<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>git stash pop
</code></pre>

</div>



<p>Isso irá trazer de volta as alterações feitas no commit que não conseguimos realizar o push. Caso esteja apavorado com a situação, poderá repetir o fluxo de visualizar o status da branch remota com <code>git status</code> e ver se há mais atualizações, poupando uma possível dor de cabeça. Caso não tenha nenhuma alteração, podemos seguir com o commit normalmente:<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>git commit -m "feat: texto-do-commit"

git push
</code></pre>

</div>



<p>Dessa forma, podemos solucionar os conflitos de versões de uma forma simples e objetiva utilizando apenas o terminal do git. <br>
É chegado o grande momento, podemos dormir tranquilos com as versões atualizadas e organizadas em nossas respectivas branches.</p>

 </details> 
 <hr /> 

 #### - [Let's #LearnLive: Deconstruct an Enterprise-Grade Serverless Architecture running on Azure](https://dev.to/azure/lets-learnlive-deconstruct-an-enterprise-grade-serverless-architecture-running-on-azure-52n8) 
 <details><summary>Article</summary> <p><strong>Register now and join us</strong>:<br>
1️⃣ | Sep 14, Ep1 👉🏽 <a href="https://aka.ms/contoso-real-estate/learn-live/Ep1?WT.mc_id=javascript-99907-ninarasi">Get Started With Contoso Real Estate</a><br>
2️⃣ | Sep 21, Ep2 👉🏽 <a href="https://aka.ms/contoso-real-estate/learn-live/Ep2?WT.mc_id=javascript-99907-ninarasi">Developing the Portal Application</a><br>
3️⃣ | Sep 28, Ep3 👉🏽 <a href="https://aka.ms/contoso-real-estate/learn-live/Ep3?WT.mc_id=javascript-99907-ninarasi">Integrating Authentication, Payments &amp; Search</a><br>
4️⃣ | Oct 05, Ep4 👉🏽 <a href="https://aka.ms/contoso-real-estate/learn-live/Ep4?WT.mc_id=javascript-99907-ninarasi">Automate Testing &amp; Deploy to Azure</a></p>




<h2>
  
  
  It's time to Fall For Intelligent Apps 🍂
</h2>

<p>Join us this fall on a learning journey to explore building intelligent apps. Combine the power of <strong>AI, cloud-scale data, and cloud-native app development</strong> to create highly differentiated digital experiences. Develop adaptive, responsive, and personalized experiences by building and modernizing intelligent applications with Azure for your users. </p>

<p>This year, we have a new set of initiatives to support you on the journey - from blog posts that demystify Intelligent Apps, to a community gallery that features content and code samples created to help <em>you</em> be more effective building your own solutions.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--6PYD6MET--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/q4hyyagf0kmdhj3bz0en.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--6PYD6MET--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/q4hyyagf0kmdhj3bz0en.png" alt="Learn Live" width="800" height="501"></a></p>

<h2>
  
  
  Learn Live: Serverless Edition
</h2>

<p>But I am most excited for this one - our new 4-part Learn Live Series where we deconstruct <em>Contoso Real Estate</em> - an enterprise-grade reference sample using a composable architecture to build a multi-scenario application, on Azure.</p>

<p><strong>Why should you learn this skill?</strong> </p>

<p>There are a lot of beginner-friendly tutorials that teach you to build real-world applications with current technologies. But building <em>enterprise-grade</em> solutions is hard. How do you bridge the gap between knowing application development, and learning best practices for deploying solutions in CI/CD pipelines, for real-world usage at scale.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--xXbus0-s--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ltd5ro0xc0ws7tt5zy8w.jpeg" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--xXbus0-s--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ltd5ro0xc0ws7tt5zy8w.jpeg" alt="Sketchnote of value of samples" width="800" height="450"></a></p>

<p>With new tools and technologies like GitHub Codespaces, and GitHub Copilot - you can also build, deploy - and understand - unfamiliar codebases and applications on you own. Join us for the next four Thursdays as we explore an open-source codebase for an enterprise-grade reference sample on Azure. Then <strong>transfer that knowledge to building your own serverless, intelligent apps on Azure</strong>.</p>

<h2>
  
  
  Ep 1: Get Started with Contoso Real Estate
</h2>

<ul>
<li>
<strong>Sep 14</strong> 👉🏽 <a href="https://aka.ms/contoso-real-estate/learn-live/Ep1?WT.mc_id=javascript-99907-ninarasi">Building Composable Cloud-native Solutions on Azure</a>
</li>
</ul>

<p>Learn about the Contoso Real Estate sample, fork the repo, launch GitHub Codespaces - and build/preview the application to validate environment.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--XQp_Fdpt--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://azure.github.io/Cloud-Native/img/fallforia/learn-live-contoso.jpg" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--XQp_Fdpt--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://azure.github.io/Cloud-Native/img/fallforia/learn-live-contoso.jpg" alt="Contoso Real Estate" width="800" height="450"></a></p>

<h2>
  
  
  Ep 2: Developing the Portal Application
</h2>

<ul>
<li>
<strong>Sep 21</strong> 👉🏽 [<a href="https://aka.ms/contoso-real-estate/learn-live/Ep2?WT.mc_id=javascript-99907-ninarasi">Developing the Portal Application</a>
</li>
</ul>

<p>Learn about micro-frontends and API-first design. Deconstruct the portal app, blog app, and serverless API.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--vzWrf_HS--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://azure.github.io/Cloud-Native/img/fallforia/learn-live-portal-app.jpg" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--vzWrf_HS--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://azure.github.io/Cloud-Native/img/fallforia/learn-live-portal-app.jpg" alt="Developing the Portal Application" width="800" height="450"></a></p>

<h2>
  
  
  Ep 3: Integrating Authentication, Payments &amp; Search
</h2>

<ul>
<li>
<strong>Sep 28</strong> 👉🏽 [<a href="https://aka.ms/contoso-real-estate/learn-live/Ep3?WT.mc_id=javascript-99907-ninarasi">Integrating Authentication, Payments &amp; Search</a>
</li>
</ul>

<p>Integrate authentication to support user profiles. Integrate payments and search features using 3rd party API.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--8eG5dsZF--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://azure.github.io/Cloud-Native/img/fallforia/learn-live-third-party-payments.jpg" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--8eG5dsZF--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://azure.github.io/Cloud-Native/img/fallforia/learn-live-third-party-payments.jpg" alt="Integrating Authentication, Payments &amp; Search" width="800" height="450"></a></p>

<h2>
  
  
  Ep 4: Automate Testing &amp; Deploy to Azure
</h2>

<ul>
<li>
<strong>Oct 05</strong> 👉🏽 [<a href="https://aka.ms/contoso-real-estate/learn-live/Ep4?WT.mc_id=javascript-99907-ninarasi">Automate Testing &amp; Deploy to Azure</a>
</li>
</ul>

<p>Learn to design and run end-to-end tests with Playwright. Provision and deploy solution to Azure with AZD.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--i1Zcm4bx--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://azure.github.io/Cloud-Native/img/fallforia/learn-live-azure-developer.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--i1Zcm4bx--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://azure.github.io/Cloud-Native/img/fallforia/learn-live-azure-developer.png" alt="Automate Testing &amp; Deploy to Azure" width="800" height="450"></a></p>




<h2>
  
  
  🧰 | Resources
</h2>

<ul>
<li>1️⃣ | Join our <a href="https://azure.github.io/Cloud-Native/Fall-For-IA/LearnLive">Learn Live: Serverless</a> Series</li>
<li>2️⃣ | Fork the <a href="https://aka.ms/contoso-real-estate/github/fork">Contoso Real Estate</a> Application</li>
<li>3️⃣ | Explore the <a href="https://aka.ms/contoso-real-estate/collection">LearnLive Resources</a> Collection</li>
</ul>

<h2>
  
  
  Register now and join us
</h2>

<p>1️⃣ | Sep 14, Ep1 👉🏽 <a href="https://aka.ms/contoso-real-estate/learn-live/Ep1?WT.mc_id=javascript-99907-ninarasi">Get Started With Contoso Real Estate</a><br>
2️⃣ | Sep 21, Ep2 👉🏽 <a href="https://aka.ms/contoso-real-estate/learn-live/Ep2?WT.mc_id=javascript-99907-ninarasi">Developing the Portal Application</a><br>
3️⃣ | Sep 28, Ep3 👉🏽 <a href="https://aka.ms/contoso-real-estate/learn-live/Ep3?WT.mc_id=javascript-99907-ninarasi">Integrating Authentication, Payments &amp; Search</a><br>
4️⃣ | Oct 05, Ep4 👉🏽 <a href="https://aka.ms/contoso-real-estate/learn-live/Ep4?WT.mc_id=javascript-99907-ninarasi">Automate Testing &amp; Deploy to Azure</a></p>




<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--rkdcNII0--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/vo1632ytoet7sqe5i7mv.jpg" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--rkdcNII0--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/vo1632ytoet7sqe5i7mv.jpg" alt="Fall For Intelligent Apps" width="800" height="450"></a></p>

 </details> 
 <hr /> 

 #### - [Installing and Configuring Kubeflow with MinIO Operator](https://dev.to/sashawodtke/installing-and-configuring-kubeflow-with-minio-operator-42ha) 
 <details><summary>Article</summary> <p>By Daniel Valdivia, Engineer, MinIO  </p>

<p>Kubeflow is a modern solution to design, build and orchestrate Machine Learning pipelines using the latest and most popular frameworks. Out of the box, Kubeflow ships with MinIO inside to store all of its pipelines, artifacts and logs, however that MinIO is limited to a single PVC and thus cannot benefit from all the features a distributed MinIO brings to the table such as <a href="https://min.io/product/active-data-replication-for-object-storage?ref=blog.min.io">Active-Active Replication</a>, unlimited storage via <a href="https://min.io/product/automated-data-tiering-lifecycle-management?ref=blog.min.io">Tiering</a> - and so much more.</p>

<p>In this blog post we are going to configure Kubeflow to use a large MinIO Tenant on the same Kubernetes cluster, but of course, this configuration applies to Kubeflow and MinIO being on different clusters as well. For your reference, please see our earlier blog post, <a href="https://blog.min.io/kubeflow-minio-azure/">Machine Learning Pipelines with Kubeflow and MinIO on Azure</a>, and the <a href="https://www.kubeflow.org/?ref=blog.min.io">Kubeflow</a> site.  </p>

<p>While we go from soup to nuts in this blog post, if you already have a Kubeflow setup and a MiniO setup, you can skip straight to the Configure Kubeflow section of this blog post to see what needs to be configured.</p>

<h2>
  
  
  Setting up the MinIO Operator
</h2>

<p>Let's start by installing the MinIO Operator and creating a tenant that Kubeflow will use. My favorite way to install MinIO Operator is via kubectl apply -k but we also have Helm Charts available, and we are also available on the <a href="https://min.io/product/multicloud-elastic-kubernetes-service?ref=blog.min.io">AWS Marketplace</a>, <a href="https://min.io/product/multicloud-google-kubernetes-service?ref=blog.min.io">Google Cloud Marketplace</a> and <a href="https://min.io/product/multicloud-azure-kubernetes-service?ref=blog.min.io">Azure Marketplace</a>.<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>kubectl apply -k github.com/minio/operator/
</code></pre>

</div>



<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--8Y-faH11--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/smjdq5jij9z4zxjf2isb.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--8Y-faH11--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/smjdq5jij9z4zxjf2isb.png" alt="Image description" width="800" height="469"></a></p>

<p>This will install the latest and greatest MinIO Operator, now we just need to log into the Operator UI and create a tenant. For this step we'll get a service account JWT token to login, but   this UI can also be secured with AD/LDAP or OIDC.<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>kubectl -n minio-operator  get secret $(kubectl -n minio-operator get serviceaccount console-sa -o jsonpath="{.secrets[0].name}") -o jsonpath="{.data.token}" | base64 --decode &amp;&amp; echo ""
</code></pre>

</div>



<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--L6pRb1G6--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/4e319fw58gjwh6gsi0km.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--L6pRb1G6--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/4e319fw58gjwh6gsi0km.png" alt="Image description" width="800" height="444"></a></p>

<p>Now let's port forward the UI and login.<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>kubectl -n minio-operator port-forward svc/console 9090
</code></pre>

</div>



<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--1LCq-4lp--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/rkyinyr92i5mleu96nrr.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--1LCq-4lp--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/rkyinyr92i5mleu96nrr.png" alt="Image description" width="800" height="246"></a></p>

<p>Now open a browser, go to <a href="http://localhost:9090">http://localhost:9090</a> and login with the JWT token we got on the previous step.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--d_aMScyR--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/1ghdq996h8wxxpy61leu.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--d_aMScyR--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/1ghdq996h8wxxpy61leu.png" alt="Image description" width="800" height="577"></a></p>

<p>After logging in, click on <strong>Create Tenant</strong> and set up a 1TiB tenant.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--xx5UldPG--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/qczatotvolcujuds6bol.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--xx5UldPG--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/qczatotvolcujuds6bol.png" alt="Image description" width="800" height="532"></a></p>

<p>Enter the name of the new tenant and the namespace for it.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--4hdVyeXO--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/zpt89bgg4nw3mqrhe2hd.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--4hdVyeXO--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/zpt89bgg4nw3mqrhe2hd.png" alt="Image description" width="800" height="532"></a></p>

<p>If the namespace doesn't exist you have the option to create the namespace.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--NCBIKhtm--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/gar71ajku2jp8blc6w02.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--NCBIKhtm--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/gar71ajku2jp8blc6w02.png" alt="Image description" width="800" height="532"></a></p>

<p>Now let's size the tenant. I'll be setting up a <strong>4 node cluster</strong> that has 4 drives on each node, in this case, because we’re on Kubernetes, node or server translates to pods and drives per server translates to PVCs per pod.</p>

<p>I'm also starting with 1TiB of capacity but you can always <a href="https://docs.min.io/minio/baremetal/installation/expand-minio-distributed.html?ref=blog.min.io">expand the capacity of the tenant</a>.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--szZ6Tvmu--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/5xr06ljvy810s6n0tb1f.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--szZ6Tvmu--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/5xr06ljvy810s6n0tb1f.png" alt="Image description" width="800" height="603"></a></p>

<p>Let's go to <strong>Identity Provider</strong> and create a basic user that will be used by Kubeflow. If you choose to configure an <a href="https://min.io/product/identity-and-access-management?ref=blog.min.io">external identity provider</a> that uses OpenID or Active Directory/LDAP, you can just go ahead and create a service account after you log in to the tenant.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--miJx6wQH--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/9a53bd4qq4c4qly30229.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--miJx6wQH--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/9a53bd4qq4c4qly30229.png" alt="Image description" width="800" height="603"></a></p>

<p>Lastly, we'll disable <strong>TLS</strong> just to keep this blog post from getting too long, but if you want to have TLS enabled on your tenant, you'll need a certificate configured on the tenant that Kubeflow trusts.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--d-hAMluh--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/euk2x1zyh9lx0wk94gc1.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--d-hAMluh--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/euk2x1zyh9lx0wk94gc1.png" alt="Image description" width="800" height="603"></a></p>

<p>And that's it, just hit <strong>Create</strong> and the tenant will be created in a few minutes.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--fRUv4MLY--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/dhazluak0mgv9q4bijkv.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--fRUv4MLY--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/dhazluak0mgv9q4bijkv.png" alt="Image description" width="800" height="515"></a></p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--wvHqaqGF--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/cqeynobkmybjbtshqwrp.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--wvHqaqGF--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/cqeynobkmybjbtshqwrp.png" alt="Image description" width="800" height="603"></a></p>

<p>That's it, now you have a distributed, high performance, hyper scale object storage that can be expanded endlessly. From here, let's configure Kubeflow to use this MinIO deployment.</p>

<h2>
  
  
  Setting up Kubeflow
</h2>

<p>In this section, we'll set up Kubeflow from scratch on Kubernetes. This works for on-premise deployments, development environments or any public cloud, although cloud providers frequently  offer a pre-configured version of Kubeflow.</p>

<p>We'll be using the <a href="https://github.com/kubeflow/manifests?ref=blog.min.io">kubeflow/manifest</a> repository. Bear in mind there are some strict requirements for this to work, for example, <strong>the highest version of Kubernetes supported by Kubeflow 1.5.0 (at the time of writing) is 1.21</strong> so make sure you’re using a Kubernetes cluster that meets this requirement.</p>

<p>One additional requirement is to have Kustomize version <a href="https://blog.min.io/how-to-kubeflow-minio/?ref=hackernoon.com#:~:text=have%20Kustomize%20version-,3.2.0,-%2C%20and%20that%27s%20it">3.2.0</a>, and that's it.</p>

<p>Let's start by cloning the kubeflow/manifest repository<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>git clone https://github.com/kubeflow/manifests
</code></pre>

</div>



<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--wyTQC4fP--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/g9hdk266ewjqmax5e540.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--wyTQC4fP--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/g9hdk266ewjqmax5e540.png" alt="Image description" width="800" height="480"></a></p>

<p>Then change directories the manifest folder and run the following command:<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>cd manifests
while ! kustomize build example | kubectl apply -f -; do echo "Retrying to apply resources"; sleep 10; done
</code></pre>

</div>



<p>This command will take a few minutes to install all the resources needed by Kubeflow. If anything fails to apply, the command will continue attempting to apply it until it succeeds entirely.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--ThQFIbmn--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ixuoof8c1t9mq13k69m4.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--ThQFIbmn--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ixuoof8c1t9mq13k69m4.png" alt="Image description" width="800" height="374"></a></p>

<p>After a few minutes, you can confirm all the pods in the <strong>kubeflow</strong> namespace are up and running:<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>kubectl -n kubeflow get pods
</code></pre>

</div>



<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--vnQKK_nL--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/4ejell2lla04xihxyap5.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--vnQKK_nL--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/4ejell2lla04xihxyap5.png" alt="Image description" width="800" height="579"></a></p>

<p>Now we will configure Kubeflow to use our new MinIO.</p>

<h2>
  
  
  Configure Kubeflow
</h2>

<p>The following section is the core of connecting Kubeflow and MinIO. Please note that the resources that need to be modified in this section are also what you'd tweak if you were starting with an existing Kubeflow deployment.</p>

<p>We are going to edit a variety of Config Maps, Secrets and Deployments on the <strong>kubeflow</strong> namespace first, and then on any existing user namespaces.</p>

<p>All of these steps assume MinIO is running in the <strong>ns-1 **namespace and running on port **80</strong>. If you were running the tenant with TLS you'd use port 443.</p>

<p>Tenant URL: minio.ns-1.svc.cluster.local</p>

<p>Tenant Port: 80</p>

<h2>
  
  
  Edit Configmaps
</h2>

<p><strong>pipeline-install-config</strong></p>

<p>Edit the <strong>pipeline-install-config</strong> config map and add the following fields to <strong>.data</strong>:<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>minioServiceHost: minio.ns-1.svc.cluster.local
minioServicePort: "80"
</code></pre>

</div>



<p>Edit command:<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>kubectl -n kubeflow edit cm pipeline-install-config
</code></pre>

</div>



<p><strong>workflow-controller-configmap</strong></p>

<p>Edit the configmap <strong>workflow-controller-configmap</strong> and configure the <strong>endpoint</strong> field inside the *<em>s3 *</em> section to point to your tenant<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>s3:
      endpoint: "minio.ns-1.svc.cluster.local:80"
</code></pre>

</div>



<p>Use this command to edit the configmap:<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>kubectl -n kubeflow edit cm workflow-controller-configmap
</code></pre>

</div>



<p><strong>ml-pipeline-ui-configmap</strong></p>

<p>Edit the <strong>ml-pipeline-ui-configmap</strong> configmap and replace the json content of viewer-pod-template.json with the following json:<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>{
  "spec": {
    "containers": [
      {
        "env": [
          {
            "name": "AWS_ACCESS_KEY_ID",
            "valueFrom": {
              "secretKeyRef": {
                "name": "mlpipeline-minio-artifact",
                "key": "accesskey"
              }
            }
          },
          {
            "name": "AWS_SECRET_ACCESS_KEY",
            "valueFrom": {
              "secretKeyRef": {
                "name": "mlpipeline-minio-artifact",
                "key": "secretkey"
              }
            }
          },
          {
            "name": "AWS_REGION",
            "valueFrom": {
              "configMapKeyRef": {
                "name": "pipeline-install-config",
                "key": "minioServiceRegion"
              }
            }
          }
        ]
      }
    ]
  }
}
</code></pre>

</div>



<p>Use this command to edit the configmap:<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>kubectl -n kubeflow edit cm ml-pipeline-ui-configmap
</code></pre>

</div>



<p>Make sure the indentation structure of the json matches the existing format.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--EiYepszN--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/fzce3ssoz2y2xusz0ifl.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--EiYepszN--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/fzce3ssoz2y2xusz0ifl.png" alt="Image description" width="800" height="312"></a></p>

<h2>
  
  
  Edit Secrets
</h2>

<p>We will update the secret that holds the credentials to MinIO, however these are meant to be <strong>base64</strong> encoded, so you can encode them with shell:<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>echo -n "kubeflow" | base64 
echo -n "kubeflow123" | base64 
</code></pre>

</div>



<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--YldZOkkK--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ai4x2vraweeqftmbrsje.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--YldZOkkK--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ai4x2vraweeqftmbrsje.png" alt="Image description" width="800" height="448"></a></p>

<p><strong>mlpipeline-minio-artifact</strong></p>

<p>Edit the secret <strong>mlpipeline-minio-artifact</strong> and set these values in the <strong>.data</strong> field<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>data:
  accesskey: a3ViZWZsb3c=
  secretkey: a3ViZWZsb3cxMjM=
</code></pre>

</div>



<p>Use this command to edit the configmap:<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>kubectl -n kubeflow edit secret mlpipeline-minio-artifact
</code></pre>

</div>



<h2>
  
  
  Edit Deployments
</h2>

<p>We will now edit the deployments last to cause a pod restart and to get everything ready.</p>

<p><strong>ml-pipeline-ui</strong></p>

<p>Edit the <strong>ml-pipeline-ui</strong> deployment and add the following environment variables:<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>- name: AWS_ACCESS_KEY_ID
  valueFrom:
    secretKeyRef:
      name: mlpipeline-minio-artifact
      key: accesskey
- name: AWS_SECRET_ACCESS_KEY
  valueFrom:
    secretKeyRef:
      name: mlpipeline-minio-artifact
      key: secretkey
- name: MINIO_NAMESPACE

- name: MINIO_HOST
  value: minio.ns-1.svc.cluster.local
- name: MINIO_PORT
  value: "80"
</code></pre>

</div>



<p><strong>Note: make sure to edit the MINIO_NAMESPACE environment variable to be empty, this is critical as that environment variable is already present in the deployment.</strong></p>

<p>Use the following command to edit the configmap:<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>kubectl -n kubeflow edit deployment ml-pipeline-ui
</code></pre>

</div>



<p><strong>ml-pipeline</strong></p>

<p>Edit the <strong>ml-pipeline</strong> deployment and add the following environment variables:<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>- name: OBJECTSTORECONFIG_HOST
  valueFrom:
    configMapKeyRef:
      name: pipeline-install-config
      key: minioServiceHost
- name: OBJECTSTORECONFIG_PORT
  value: "80"
</code></pre>

</div>



<p>Use the following command to edit the deployment:<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>kubectl -n kubeflow edit deployment ml-pipeline
</code></pre>

</div>



<h2>
  
  
  Configure Every User Namespace
</h2>

<p>This is also very important, for every user namespace, patch the <strong>ml-pipeline-ui-artifact</strong> deployment in that namespace and the artifact secret. For example, in my case my namespace is <strong>kubeflow-user-example-com</strong> since we used the example manifest.</p>

<p>Edit the secret <strong>mlpipeline-minio-artifact</strong> and set these values in the <strong>.data</strong> field:<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>data:
  accesskey: a3ViZWZsb3c=
  secretkey: a3ViZWZsb3cxMjM=
</code></pre>

</div>



<p>Edit the <strong>ml-pipeline-ui-artifact</strong> and add the following environment variables<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>- name: MINIO_NAMESPACE
- name: MINIO_HOST
  value: minio.ns-1.svc.cluster.local
- name: MINIO_PORT
  value: "80"
</code></pre>

</div>



<p>Use the following command to edit the artifact:<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>kubectl -n kubeflow-user-example-com edit secret mlpipeline-minio-artifact

kubectl -n kubeflow-user-example-com edit deployment ml-pipeline-ui-artifact
</code></pre>

</div>



<p>At this point Kubeflow is properly configured to use your tenant. There’s one last step and then we are good to test our deployment.</p>

<h2>
  
  
  Migrate All Data from Kubeflow's Internal MinIO to the New Tenant
</h2>

<p>Now that we have configured everything, we just need to make sure the data Kubeflow is expecting to be in its buckets is actually there. Let’s copy that data over and then shutdown the internal MinIO that we’re replacing.</p>

<p>To achieve this we will use MinIO Client (mc), a CLI tool for managing MinIO. We'll do all these operations from a pod running inside Kubernetes, but you can do this via port-forwarding and using mc from your own machine if you choose to do so.</p>

<p>Let's run a pod with an Ubuntu shell:<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>kubectl -n kubeflow run my-shell  -i --tty --image ubuntu -- bash
</code></pre>

</div>



<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--bhJNG3r7--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/7rr6e1lfvdv44dfs36ov.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--bhJNG3r7--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/7rr6e1lfvdv44dfs36ov.png" alt="Image description" width="800" height="453"></a></p>

<p>This shell runs on a pod running inside our Kubernetes cluster in the Kubeflow namespace.</p>

<p>Now we will:</p>

<ol>
<li>Install <strong>wget</strong>
</li>
<li>Download <strong>mc</strong>
</li>
<li>Make <strong>mc</strong> executable</li>
<li>Add an alias to the current MinIO</li>
<li>Add an alias to the new MinIO</li>
<li>Copy all the data</li>
</ol>

<p>To accomplish this we run the following commands:<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>apt update &amp;&amp; apt install -y wget
wget https://dl.min.io/client/mc/release/linux-amd64/mc
chmod +x mc
mv mc /usr/local/bin/
mc config host add kubeflow http://minio-service.kubeflow.svc.cluster.local:9000 minio minio123
mc config host add tenant http://minio.ns-1.svc.cluster.local kubeflow kubeflow123
mc mirror kubeflow tenant

</code></pre>

</div>



<p>Finally, turn off the internal MinIO as it is no longer required.<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>kubectl -n kubeflow scale deploy minio --replicas=0
</code></pre>

</div>



<p>All right! We are done moving to the full MinIO deployment.  </p>

<h2>
  
  
  Validate that Kubeflow is Using the new MinIO
</h2>

<p>Next we’ll validate  the setup and run some pipelines.</p>

<p>If you go to MinIO Operator, you can see the tenant now has data:</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--qH-Hzf_J--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/79cdcgr8rxxkbrem3sbs.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--qH-Hzf_J--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/79cdcgr8rxxkbrem3sbs.png" alt="Image description" width="800" height="487"></a></p>

<p>Click the tenant, and then click <strong>Console</strong> in the top right of the browser window to open MinIO Console in order to browse that tenant.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--7rRsrB09--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/m7s570f53gqybag4ycp4.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--7rRsrB09--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/m7s570f53gqybag4ycp4.png" alt="Image description" width="800" height="487"></a></p>

<p>From this view, you can see the <strong>mlpipeline</strong> bucket. Click browse to see its contents.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--q24iTBMp--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/uxb4l73lzid24whkn0pk.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--q24iTBMp--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/uxb4l73lzid24whkn0pk.png" alt="Image description" width="800" height="487"></a></p>

<p>You'll see the existing demo pipelines have been copied over.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--Tap4QHcQ--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/cwkhn11fvwxdkbgi2knh.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--Tap4QHcQ--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/cwkhn11fvwxdkbgi2knh.png" alt="Image description" width="800" height="487"></a></p>

<p>Now let's go into Kubeflow and run some pipelines, you can use port forwarding  to expose the Kubeflow central dashboard:<br>
</p>

<div class="highlight js-code-highlight">
<pre class="highlight plaintext"><code>kubectl port-forward svc/istio-ingressgateway -n istio-system 8080:80
</code></pre>

</div>



<p>Then in your browser go to <a href="http://localhost:8080">http://localhost:8080</a>.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--9B3xxCyf--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/41ynoar9ycwafgbo56he.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--9B3xxCyf--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/41ynoar9ycwafgbo56he.png" alt="Image description" width="800" height="487"></a></p>

<p>Login with the default credentials for this example setup:</p>

<p><strong>Email Address:</strong> <a href="mailto:user@example.com">user@example.com</a></p>

<p><strong>Password:</strong> 12341234</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--AwLoN5AK--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/bh61ay5kn6zpshu6z957.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--AwLoN5AK--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/bh61ay5kn6zpshu6z957.png" alt="Image description" width="800" height="487"></a></p>

<p>Then go to the Pipelines menu in the left menu bar. We’re going to run the most basic pipeline, "[Tutorial] DSL - Control structures":</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--Jxu_WRbI--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ym5s5871rfzquwb0mjjr.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--Jxu_WRbI--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/ym5s5871rfzquwb0mjjr.png" alt="Image description" width="800" height="487"></a></p>

<p>Click on the pipeline’s name.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--gARHEPh5--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/50e1oew6pobvrg2cnali.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--gARHEPh5--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/50e1oew6pobvrg2cnali.png" alt="Image description" width="800" height="487"></a></p>

<p>From here, click Create Experiment on the top right. This will create a new experiment since it's the first time it is running, but in subsequently you can re-use this experiment.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--f3hDdlh7--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/8ud0h7tdt8iiefyjwhnj.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--f3hDdlh7--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/8ud0h7tdt8iiefyjwhnj.png" alt="Image description" width="800" height="487"></a></p>

<p>And click on Start:</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--RBIeVs4N--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/hqh5022avu1a1g6242k6.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--RBIeVs4N--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/hqh5022avu1a1g6242k6.png" alt="Image description" width="800" height="640"></a></p>

<p>After the run is complete, explore the pipeline to verify that it ran successfully.</p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--UK9NfXlq--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/3ii6pwlx70no68vnceqz.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--UK9NfXlq--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/3ii6pwlx70no68vnceqz.png" alt="Image description" width="800" height="640"></a></p>

<p><a href="https://res.cloudinary.com/practicaldev/image/fetch/s--fM36CDkE--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/d8vl0teo6el4wiridv4b.png" class="article-body-image-wrapper"><img src="https://res.cloudinary.com/practicaldev/image/fetch/s--fM36CDkE--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_800/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/d8vl0teo6el4wiridv4b.png" alt="Image description" width="800" height="640"></a></p>

<h2>
  
  
  Kubeflow and MinIO for Multi-Cloud Machine Learning
</h2>

<p>This blog post taught you how to replace the MinIO that ships with Kubeflow  with the MinIO Operator. You’re now prepared to take your Kubeflow use to the next level and back it with Kubernetes-native high performance and highly scalable  MinIO object storage.</p>

<p>When it comes to Machine Learning pipelines and infrastructure, use MinIO's <a href="https://min.io/product/automated-data-tiering-lifecycle-management?ref=blog.min.io">Lifecycle Management</a> to deploy tenants backed by super fast NVMe drives as your hot tier for fast training and model serving, and  also set up a warm tier backed up by SSDs or HDDs for your aging datasets. MinIO does this transparently  without disrupting your applications.Tiering  is configured on a per-bucket basis or even for a single prefix within a bucket, providing  granular control over  which data gets moved to a slower tier.</p>

<p>With MinIO's <a href="https://blog.min.io/minio-multi-site-active-active-replication/">Active-Active Replication</a>, you can configure  buckets serving production machine learning models to be replicated instantly across multiple sites for disaster recovery and fast failover.</p>

<p>I truly hope this blog post helped you discover how easy it is to set up MinIO object storage on Kubernetes and to consume it with Kubeflow. If you have any questions, please join our <a href="https://minio.slack.com/?ref=blog.min.io">Slack community</a> and ask!</p>

 </details> 
 <hr /> 
<!-- BLOG-POST-LIST:END -->
</table>
</details>


<!-- TODO
Change the 3stats boxes around, possibly two on top and one on bottom
Fix RSSfeed
Fix Spotify Playlists
Fix Socials [Portfolio, Discord, Linkedin]
In the future, add Public Repositories of Selected Projects
-->
